--- 
title: "La prise de son musicale"
author: "Jean-Loup Pecquais"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
# bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  Livre sur la prise de son musicale, par Jean-Loup Pecquais.
link-citations: yes
github-repo: jpecquais/doc-technique-son
---

# Avant-propos

Ce livre est nÃ© de la nÃ©cessitÃ© d'un support de cours pour la formation "Technique de Prise de Son", dispensÃ©e par Jean-Loup Pecquais. Il intÃ¨gre donc l'ensemble des notions abordÃ©es, expliquÃ©es en dÃ©tail, ainsi que des exemples sonores.

Ce livre est Ã©crit dans la philosophie de l'Open Source. L'intÃ©gralitÃ© de son contenu est donc disponible gratuitement. Son code source est accessible dans un dÃ©pÃ´t GitHub. Ainsi, il est possible Ã  tout Ã  chacun de reporter les Ã©ventuelles erreurs ou de proposer des modifications.

## Mise Ã  jour

La distribution numÃ©rique de ce livre permet une mise Ã  jour rÃ©guliÃ¨re de son contenu. Cela implique deux choses :

+ Certaines sections peuvent Ãªtre incomplÃ¨tes, et seront complÃ©tÃ©es plus tard
+ C'est une bonne idÃ©e de revenir consulter ce site rÃ©guliÃ¨rement

## Structures

Dans un premier temps, ce livre reprend l'ensemble de la chaÃ®ne audio, en y explicitant le rÃ´le et le fonctionnement de chacun de ses composants. L'objectif est de fournir une base technique objective au preneur de son.

Dans un second temps, le livre dÃ©taille un ensemble de techniques de prise de son, insistant particuliÃ¨rement sur les mÃ©canismes gÃ©nÃ©raux de la prise et sur l'Ã©coute critique. Cependant, un certain nombre "trucs & astuces" de prises de son sont aussi prÃ©sentÃ©es. Ces derniers ne doivent jamais se supplanter Ã  l'Ã©coute critique.

<!--chapter:end:index.Rmd-->


# Description dâ€™une production musicale type

Afin de comprendre quels vont Ãªtre les enjeux du preneur de son, il convient de comprendre dans quel contexte il intervient. Certes, il est le premier mÃ©tier du son Ã  rentrer en scÃ¨ne, mais lâ€™Å“uvre Ã  enregistrer a dÃ©jÃ  trÃ¨s probablement eu une longue vie. Elle a Ã©tÃ© composÃ©e, arrangÃ©e, peut-Ãªtre mÃªme dÃ©jÃ  interprÃ©tÃ©e au cours de concerts.

Ã€ ce stade, le preneur de son aura un regard neuf sur la matiÃ¨re. Il aura donc le potentiel de permettre aux crÃ©ateurs de prendre du recul sur leur travail. Il convient dâ€™ailleurs de rappeler quâ€™un preneur de son, aussi talentueux et crÃ©atif soit il, est un **assistant de crÃ©ation**. Cela signifie quâ€™il met Ã  disposition une compÃ©tence technique Ã  un dâ€™artiste pour lui permettre dâ€™avancer sur son projet. Cela implique Ã©galement que celui ou celle qui a le mot final sur le choix des orientations esthÃ©tiques est lâ€™artiste en question. Il convient donc, en tant que preneur de son, dâ€™Ãªtre force de proposition, tout en sachant respecter le choix (quâ€™ils soient bons ou mauvais) des artistes.

Dâ€™un point de vue sonore, le travail de prise de son est absolument critique. Ce sera Ã  ce moment que va se jouer la majoritÃ© des choix esthÃ©tiques. Il convient donc de rÃ©unir les conditions optimales pourÂ :

+ offrir aux musiciens et musiciennes la chance de donner leur meilleure interprÃ©tation possible
+ rÃ©aliser une prise de son en adÃ©quation avec lâ€™orientation esthÃ©tique du projet

La plupart des choix faits Ã  la prise de son ne pourront pas Ãªtre renÃ©gociÃ©s a posteriori. Il convient donc de mettre dâ€™accord les artistes, le directeur artistique et le preneur de son sur les moyens Ã  mettre en Å“uvre.

```{r, echo=FALSE, out.width="80%", fig.cap = "Entonnoir de la production musicale"}
knitr::include_graphics(path = "_resources/diagrams/productionSonore.svg")
```

## les acteurs de la rÃ©alisation dâ€™une Å“uvre enregistrÃ©e

Nous allons ici rapidement discuter des diffÃ©rents rÃ´les apparaissant dans la production dâ€™une Å“uvre musicale enregistrÃ©e. Ceux-ci sont volontairement trÃ¨s sÃ©parÃ©s, bien que dans les cas pratiques, une personne puisse en incarner plusieurs.

**Le compositeur** est la personne qui a composÃ© la mÃ©lodie et lâ€™harmonie de lâ€™Å“uvre.

**Lâ€™arrangeur** est chargÃ© de lâ€™orchestration (choix des instruments) et lâ€™Ã©criture des diffÃ©rentes partitions.

**Lâ€™interprÃ¨te** a la responsabilitÃ© de retranscrire une partition le plus justement possible, Ã  la fois dans sa dimension technique et sensible.

**Le directeur artistique** (ou DA) supervise lâ€™ensemble de lâ€™enregistrement. Il aura, par exemple, Ã  choisir le preneur de son, le mixeur ou dans quel studio enregistrer. Lors de la session dâ€™enregistrement, il aura Ã  diriger les musiciens (comme un rÃ©alisateur dirige ses acteurs au cinÃ©ma) afin de leur faire jouer la meilleure interprÃ©tation possible pour lâ€™Å“uvre. Lors du mixage, il sera le principal interlocuteur du mixeur. Pour faire courtÂ : il est le garant de lâ€™orientation esthÃ©tique du projet.

**Le producteur** finance lâ€™ensemble de projets. Câ€™est donc un investisseur qui attend un retour sur investissement.

> Lâ€™appellation abusive de Â«Â producteurÂ Â» pour parler du directeur artistique vient dâ€™un anglicisme du mot Â«Â producerÂ Â». Le producteur est donc bien lâ€™Ã©quivalent du directeur artistique dans les pays anglo-saxons. Si le DA a besoin dâ€™un certain talent, le producteur a surtout besoin dâ€™argent.

**Le preneur de son** est chargÃ© dâ€™enregistrer les musiciens et musiciennes. Il a donc un rÃ´le premier trÃ¨s techniqueÂ : il doit inscrire sur un support les ondes sonores produites par ces musiciens. Il a Ã©galement un rÃ´le esthÃ©tique trÃ¨s important, dâ€™un point de vue sonore, car le choix du dispositif de prise de son aura un fort effet sur la suite de la vie de lâ€™Å“uvre.

**Le mixeur** intervient aprÃ¨s la prise de son et doit rÃ©aliser une sommation de lâ€™ensemble des points de captations (microphone) vers un format Ã©coutable par le grand public (mono, stÃ©rÃ©o, 5.1, Ambisonique, Dolby Atmos, etc.). Son rÃ´le esthÃ©tique est fortement contraint par le travail de prise de son. Si celle-ci est rÃ©ussie, il pourra amplifier et bonifier les choix de production. Dans le cas contraire, il devra lutter pour essayer de faire sortir le meilleur dâ€™une matiÃ¨re imparfaite.

**Le technicien de mastering** est le dernier maillon de la chaÃ®ne. Son rÃ´le premier sera de prÃ©parer le travail de mixage Ã  aux supports de diffusion. Il se devra Ã©galement dâ€™offrir une oreille nouvelle sur le travail rÃ©alisÃ© au mixage. 

## La prÃ©production

La prÃ©production concerne toutes les Ã©tapes dâ€™une Å“uvre enregistrÃ©e qui ont lieu avant ledit enregistrement. On parlera donc en premier lieu de la composition et particuliÃ¨rement de lâ€™arrangement.

La qualitÃ© dâ€™un arrangement aura une influence Ã©norme sur la facilitÃ© Ã  mixer une Å“uvre. Si les instruments sont astucieusement rÃ©partis sur lâ€™ensemble du spectre sonore, cela sera une difficultÃ© de moins Ã  gÃ©rer au mixage par exemple.

Il est aussi courant pour des artistes de rÃ©aliser des Â«Â dÃ©mosÂ Â». Celles-ci sont souvent des enregistrements rÃ©alisÃ©s en home studio afin de dÃ©finir un cap esthÃ©tique pour la suite de la production sonore. Câ€™est un atout extrÃªmement prÃ©cieux pour un preneur de son, cela permet de rapidement identifier quel est le projet esthÃ©tique de lâ€™Å“uvre.

## La production

Câ€™est ici que le travail du preneur de son commence. Lâ€™Ã©tape de production consiste Ã  fixer les interprÃ©tations dÃ©finitives. Le premier objectif est donc de sâ€™assurer du bon enregistrement de tous les canaux prÃ©vus. Bien sÃ»r, lâ€™enjeu nâ€™est pas seulement technique, mais aussi esthÃ©tique. Et il nâ€™est pas moindre, les choix pris lors de la prise de son seront des carcans impossibles Ã  outrepasser lors de la phase de mixage. Enfin, lâ€™Ã©lÃ©ment le plus dÃ©terminant de cette Ã©tape est dâ€™obtenir des musiciens leurs meilleures interprÃ©tations. La prÃ©sence dâ€™un directeur artistique est dâ€™une aide prÃ©cieuse afin de diriger et dâ€™orienter les musiciens. Il permet aussi de faire le lien entre les artistes et lâ€™Ã©quipe technique, en exprimant les besoins des uns aux autres.

Sur les projets les plus modestes, le poste de directeur artistique est souvent sacrifiÃ©. Il en va donc Ã  lâ€™ingÃ©nieur du son de, parfois, remplir ce rÃ´le. 

## La postproduction

ArrivÃ© Ã  ce stade, la majoritÃ© du travail est dÃ©jÃ  accompli, il ne reste que le mixage et le mastering. Classiquement, chacune de ces tÃ¢ches incombe Ã  un technicien diffÃ©rent. Le travail du mixeur consistera Ã  rÃ©aliser la sommation, gÃ©nÃ©ralement en stÃ©rÃ©o, de lâ€™ensemble des canaux enregistrÃ©s lors de la prise de son. Afin de faire cohabiter tous ces signaux, il est commun dâ€™utiliser des traitements pour les rÃ©partir sur lâ€™ensemble du spectre et de gÃ©rer leur dynamique. Parfois, ces traitements remplissent un rÃ´le esthÃ©tique, en dÃ©formant le signal dâ€™origine pour aboutir Ã  une nouvelle matiÃ¨re.

Une fois le travail du mixeur terminÃ©, le mastering commence. Le but et dâ€™homogÃ©nÃ©iser lâ€™ensemble des titres dâ€™un disque, en volume, en dynamique et en couleur. Ensuite, il convient aussi de dÃ©finir le niveau de sortie gÃ©nÃ©ral du disque. La derniÃ¨re Ã©tape consistera Ã  monter lâ€™ordre des morceaux pour le disque, dâ€™y inscrire les mÃ©tadonnÃ©es (nom de lâ€™artiste, des titres, genre musical, etc.) et de gÃ©nÃ©rer le fichier final, dÃ©dier Ã  lâ€™exploitation.

<!--
# Les questions frÃ©quentes lors de lâ€™apprentissage de la prise de son

AprÃ¨s quelques annÃ©es Ã  dispenser cette formation consacrÃ©e Ã  la prise de son, lâ€™auteur Ã  dÃ©jÃ  eu lâ€™occasion de rencontrer un certain nombre de fois les mÃªmes questions et interrogations. Une grande partie de celles-ci trouveront leur rÃ©ponse dans le reste de ce livre, cependant, une certaine catÃ©gorie est plus difficile Ã  intÃ©grer. Celle-ci concerne le matÃ©riel liÃ© Ã  la prise de son.

Ces questions expriment souvent, de maniÃ¨re implicite, un certain dÃ©sarroi par rapport Ã  la quantitÃ© astronomique de produits disponible. Ce dÃ©sarroi nâ€™est que plus grand lorsque de violentes campagnes marketings sâ€™en mÃªlent.

Ce livre nâ€™a pas pour vocation Ã  faire la promotion de constructeurs ou de fabriquants dâ€™Ã©quipements audio. Ainsi, ces derniers ne seront pas Ã©voquÃ©s, et cela pour deux raisonsÂ :
â€”Â la grande majoritÃ© du contenu internet traitant de lâ€™audio parle de matÃ©riel audio.
â€”Â le matÃ©riel nâ€™est **jamais** la raison dâ€™un rendu sonore mÃ©diocre. De la mÃªme maniÃ¨re quâ€™en aÃ©ronotique, un accident dÃ©coule toujours dâ€™une erreur humaine, une prise de son ratÃ©e dÃ©coule forcÃ©ment des erreurs du preneur de son.


Il convient ici de clairement dÃ©finir ses besoins. Dans tous les cas, il ne sera pas comptÃ© lâ€™achat dâ€™un ordinateur, car la plupart des personnes possÃ¨dent un ordinateur suffisamment puissant pour enregistrer plusieurs pistes audio simultanÃ©ment.

**Premier critÃ¨resÂ : combien dâ€™entrÃ©esÂ ?**

Si votre objectif nâ€™est pas dâ€™enregistrer plusieurs instruments Ã  la fois, deux entrÃ©es microphones peuvent suffir Ã  90Â % des cas dâ€™usages.

Si vous Ãªtes batteur, alors huits entrÃ©es peuvent Ãªtre apprÃ©ciables.

Si vous dÃ©sirez monter une rÃ©gie de prise de son, afin dâ€™enregistrer plusieurs musiciens Ã  la fois, alors 16Â entrÃ©es semblent Ãªtre un minimum requis.

-->

<!--chapter:end:00-production_musicale.Rmd-->

```{r setup, include=FALSE}
library(reticulate)
knitr::knit_engines$set(python = reticulate::eng_python)
```

# Quantifier et qualifier le son

Le son peut s'apprÃ©hender de plusieurs faÃ§ons diffÃ©rentes. ParticuliÃ¨rement, sa description physique et psychoacoustique est trÃ¨s prÃ©cieuse pour tous les praticiens du son. Il convient donc, afin de pouvoir proposer un dispositif cohÃ©rent de prise de son, de comprendre la physique Ã©lÃ©mentaire du son ainsi que d'Ãªtre capable de le dÃ©crire efficacement. 

## PhÃ©nomÃ¨ne physique

### Quelques dÃ©finitions

Le son est une vibration mÃ©canique d'un fluide. Dans le cadre de ce cours, nous ne considÃ©rerons que l'air comme mÃ©dium de propagation. Cette onde cause une variation de la pression dans l'espace. Nous, les Ãªtres humains, le percevons grÃ¢ce Ã  notre ouÃ¯e. Il s'agit donc, par dÃ©finition, d'un phÃ©nomÃ¨ne ondulatoire et peut Ãªtre caractÃ©risÃ© par un nombre d'oscillations par seconde, aussi appelÃ© frÃ©quence. On estime que notre espÃ¨ce est sensible aux frÃ©quences allant de 20 Hz (trÃ¨s grave) jusqu'Ã  20 000 Hz (trÃ¨s aigu).

On parlera d'**Ã©vÃ¨nement sonore** pour parler gÃ©nÃ©ralement de phÃ©nomÃ¨nes physiques produisant une onde sonore.

Les sons composÃ©s d'une seule frÃ©quence se nomment **sons purs**. Cependant, de tels signaux n'existent pas dans la nature, et sont souvent utilisÃ©s afin de rÃ©aliser des mesures ou des tests psychoacoustiques. 

```{python, echo=FALSE, fig.align="center", fig.caption="Onde sinusoÃ¯dale et visualisation de son spectre"}
import matplotlib.pyplot as plt
import numpy as np

fs = 48000  # Sample rate
T = 1/fs    # Sample period
f0 = 1000

t = np.arange(0,1,1/fs)
h = np.sin(2*np.pi*f0*t)

# Transfer function H via FFT - same # of bins
H_FFT = 20*np.log(2*np.fft.fft(h, fs)/fs)

plt.figure()
fig, axs = plt.subplots(nrows=2, ncols=1)
#axs[0].title("Onde sinusoÃ¯dale et visualisation de son spectre")
axs[0].plot(t, h, label = str(f0) + " Hz")
var = axs[0].set_xlim(0,1/f0)
#axs[0].set_xlabel("Temps (s)")
axs[0].set_ylabel("Amplitude")
axs[0].legend()

axs[1].plot(H_FFT)
var = axs[1].set_xlim(20,20000)
axs[1].set_xscale("log")
var = axs[1].set_ylim(-96,24)
var = 0
axs[1].set_xlabel("Frequences (Hz)")
axs[1].set_ylabel("Amplitude (dB)")
```

<!--
```{r, echo=FALSE, out.width="50%", fig.show = 'hold', fig.cap = "ReprÃ©sentation d'un son pur : (1) domaine temporel ; (2) domaine frÃ©quentiel"}
knitr::include_graphics(rep(c("_resources/drawings/sinus_tps.svg","_resources/drawings/sinus_fqc.svg")))
```
-->

Dans notre environnement, les sons sont donc composÃ©s de plusieurs frÃ©quences. La frÃ©quence la plus grave d'un son est sa **frÃ©quence fondamentale**. Les autres sont alors appelÃ©es **partiels**. Si ces partielles ont pour frÃ©quence un multiple de la frÃ©quence fondamentale, alors on les nomme **harmoniques**.

> ğŸ’¡ Plus gÃ©nÃ©ralement, on admettra que la composition frÃ©quentielle, ou spectrale, de tout son peut Ãªtre dÃ©composÃ©e par une somme de sinusoÃ¯de. L'outil permettant de passer de la reprÃ©sentation temporelle d'un signal Ã  sa reprÃ©sentation frÃ©quentiel s'appelle la **transformÃ©e de Fourrier.** 

```{python, echo=FALSE, fig.align="center", fig.caption="Signal carrÃ© et visualisation de son spectre"}
import matplotlib.pyplot as plt
import numpy as np

fs = 48000  # Sample rate
T = 1/fs    # Sample period
f0 = 1000

t = np.arange(0,1,1/fs)
sine = np.sin(2*np.pi*f0*t)
square = np.array([1 if np.sin(2*np.pi*f0*x) >= 0 else -1 for x in t])

# Transfer function H via FFT - same # of bins
H_FFT = 20*np.log(2*np.fft.fft(square, fs)/fs)

plt.figure()
fig, axs = plt.subplots(nrows=2, ncols=1)
axs[0].plot(t, square, label = str(f0) + " Hz")
var = axs[0].set_xlim(0,1/f0)
#axs[0].set_xlabel("Temps (s))")
axs[0].set_ylabel("Amplitude")
axs[0].legend()

axs[1].plot(H_FFT)
var = axs[1].set_xlim(20,20000)
axs[1].set_xscale("log")
var = axs[1].set_ylim(-96,24)
var = 0
axs[1].set_xlabel("Frequences (Hz)")
axs[1].set_ylabel("Amplitude (dB)")
```

<!--
```{r, echo=FALSE, out.width="50%", fig.show = 'hold', fig.cap = "ReprÃ©sentation d'une onde carrÃ©e qui ne contient que les harmoniques impaires."}
knitr::include_graphics(rep(c("_resources/drawings/square_tps.svg","_resources/drawings/square_fqc.svg")))
```
-->

La frÃ©quence fondamentale donne la **hauteur** du son (sa note en musique par exemple). Les partiels enrichissent cette frÃ©quence fondamentale et crÃ©Ã©s le **timbre** d'un son. C'est en partie grÃ¢ce au timbre que l'on peut reconnaÃ®tre diffÃ©rents instruments de musiques jouant la mÃªme note.

Un son se caractÃ©rise Ã©galement par l'Ã©volution de son amplitude au cours du temps. On parle alors de son **enveloppe**. Un modÃ¨le courant d'enveloppe est l'ADSR : *Attack*, *Decay*, *Sustain*, *Release*, soit *Attaque*, *DÃ©croissance*, *Maintient* et *RelÃ¢chement*.

```{r, echo=FALSE, out.width="65%", fig.align="center", fig.cap = "Exemple d'enveloppe ADSR"}
knitr::include_graphics("_resources/drawings/adsr.svg")
```

Lorsque son temps et trÃ¨s bref, l'ensemble *attaque* et *dÃ©croissance* forme les **transitoires**. Cette partie du signal est responsable de la sensation percussive du son.

### Relation entre temps, distance et frÃ©quence

Il est important de garder Ã  l'esprit que les notions de temps, de frÃ©quence et de distance sont Ã©troitement liÃ©es. Nous avons vu ci-dessus que tous les sons peuvent Ãªtre dÃ©crits par une somme de sinusoÃ¯de. Leur frÃ©quence la plus grave, dite fondamentale, permet de dÃ©finir la **pÃ©riode**. La pÃ©riode est le temps que met un signal Ã  rÃ©pÃ©ter son motif oscillatoire (voir schÃ©mas 3.1 et 3.2). Le lien mathÃ©matique entre frÃ©quence et pÃ©riode est trÃ¨s simple, car l'un est l'inverse de l'autre :

$$ f = \frac 1 T $$

Si nous Ã©tudions les frÃ©quences extrÃªmes, audibles par notre ouÃ¯e, nous trouvons que pour $f_{min} = 20 \,Hz$, sa pÃ©riode $T_{f_{min}} = 50 \,ms$. Pour $f_{max} = 20\,000 \,Hz$, $T_{f_{max}} = 0.5 \,ms$.

Une onde sonore est Ã©galement caractÃ©risÃ©e par sa **cÃ©lÃ©ritÃ©**. Celle-ci est constante dans un milieu donnÃ©. Dans l'air, Ã  une tempÃ©rature de $15 \,Â°C$ et au niveau de la mer, sa cÃ©lÃ©ritÃ© $c$ est de $340\,m.s^{-1}$. On admettra cette valeur pour rÃ©aliser l'ensemble de nos diffÃ©rents calculs.

Comme son unitÃ© l'indique, la cÃ©lÃ©ritÃ© du son est homogÃ¨ne Ã  une distance divisÃ©e par un temps, soit :

$$ c =\frac d t $$

Suivant cette formule, nous pouvons alors calculer la **longueur d'onde** correspondant Ã  une frÃ©quence. La longueur d'onde se note $\lambda$. 

$$ \lambda = cT \; \iff \; \lambda = \frac c f$$

Si nous Ã©tudions Ã  nouveau les bornes minimale et maximale de notre audition, nous trouvons que $\lambda_{f_{min}} = 17 \,m$ et $\lambda_{f_{max}} = 17 \,mm$.

Nous pouvons Ã©galement calculer le temps de propagation du son. En pratique, nous serons souvent intÃ©ressÃ©s par le temps de propagation sÃ©parant deux points dans l'espace (par exemple, le temps sÃ©parant deux microphones par rapport Ã  un instrument).

```{r, echo=FALSE, out.width="25%", fig.align="center", fig.cap = "Distance entre deux microphones."}
knitr::include_graphics("_resources/drawings/mic_dist.svg")
```

$$ t = \frac {d_2-d_1}{c}$$

## Perception du son

Nous avons abordÃ© quelques notions de physique permettant de mieux caractÃ©riser le phÃ©nomÃ¨ne sonore. Comme indiquÃ© au dÃ©but de ce chapitre, le son peut Ã©galement Ãªtre discutÃ© sous l'angle de notre ouÃ¯e, et donc, de notre perception. Cette branche de la science se nomme la psychoacoustique et cherche Ã  Ã©tudier la faÃ§on dont nous percevons le son.

Notre corps, et a fortiori notre cerveau, sont des machines extrÃªmement complexes. Nous sommes Ã©quipÃ©s d'une multitude de capteurs permettant de sentir le contact d'une matiÃ¨re, des odeurs, d'entendre, de goÃ»ter, de voir, de positionner nos membres dans l'espace, de ressentir la douleur, etc. Pris indÃ©pendamment, chacun de ces sens est dÃ©jÃ  un phÃ©nomÃ¨ne complexe Ã  dÃ©crire, mais il existe en plus une grande interdÃ©pendance entre ceux-ci. Par exemple, l'interdÃ©pendance entre la vision et l'audition est Ã  l'origine d'un certain nombre de mÃ©canismes biaisant notre Ã©coute.

Nous nous bornerons au fil de ce cours Ã  quelques notions liÃ©es Ã  l'ouÃ¯e et Ã  son interdÃ©pendance Ã  d'autre sens quand cela sera pertinent.

### Spectre, timbre et vocabulaire

D'un point de vue perceptif, le spectre d'un Ã©vÃ¨nement sonore est facilement remarquable. Il est, par contre, beaucoup plus difficile Ã  qualifier. Il n'est pas rare de rencontrer les adjectifs "chaud", "brillant", "rond", "aÃ©rÃ©", "ouvert", "sombre", voir d'autres encore plus Ã©sotÃ©rique, pour tenter de communiquer la sensation ressentie Ã  l'Ã©coute de tel ou tel son.

Cette difficultÃ© liÃ©e Ã  l'absence de vocabulaire commun quant Ã  la qualification le son emmÃ¨ne systÃ©matiquement la redÃ©finition de ce vocable en fonction de son interlocuteur. En effet, le mot "rond" ne signifiera pas forcÃ©ment la mÃªme chose selon Ã  qui on s'adresse. Une stratÃ©gie possible consiste Ã  questionner son interlocuteur sur l'utilisation de ses adjectifs tout en cherchant Ã  y associer des exemples sonores.

Nous pouvons tout de mÃªme nous essayer Ã  cet exercice pour nous permettre d'avoir un vocabulaire commun au fil de ce cours. Vous aurez sans doute compris qu'il n'y aura, dans les termes employÃ©s, aucun critÃ¨re absolu.

```{r, echo=FALSE, out.width="100%", fig.align="center", fig.cap = "Distance entre deux microphones."}
knitr::include_graphics("_resources/drawings/spectre.svg")
```

**Proposition d'association entre bandes de frÃ©quences et sensation**.
 
+ **20Â Hz â€” 80Â Hz** : Subharmonique, sensation tripale
+ **80Â Hz â€” 160Â Hz** : Grave, sensation dâ€™assise
+ **160Â Hz â€” 380Â Hz** : bas-mÃ©dium, sensation de Â«Â chaleurÂ Â», voir Â«Â boueuxÂ Â»
+ **380Â Hz â€” 1400Â Hz** : Medium, sensation de Â«Â boÃ®teÂ Â» quand trop prÃ©sent, sonne Â«Â creuxÂ Â» quand trop absent
+ **1400Â Hz â€” 3200Â Hz** : Haut-medium : zone de sensibilitÃ© maximale de lâ€™oreille.
+ **3200Â Hz â€” 8000Â Hz** : Aigu, apporte de la prÃ©cision voir de lâ€™agressivitÃ©
+ **8000Â Hz â€” 20Â 000Â Hz** : Air, apporte une sensation dâ€™ouverture voir de finesse

Il est intÃ©ressant de former son oreille Ã  reconnaÃ®tre une plage de frÃ©quence, ainsi que d'y associer son propre vocabulaire et une sensation. Les appellations proposÃ©es ci-dessus ne sont Ã  prendre que comme guides et n'ont pas valeur de rÃ©fÃ©rence. Cela favorise une Ã©coute critique et analytique.

> ğŸ’¡ Aussi, les frÃ©quences graves ont un effet masquant sur les frÃ©quences plus aiguÃ«s. Ce phÃ©nomÃ¨ne est dÃ» au fonctionnement de notre oreille, et plus particuliÃ¨rement de la cochlÃ©e.

### Pression acoustique & niveau sonore

Nous l'avons abordÃ© plus haut, lorsqu'une onde sonore se dÃ©place dans l'air, on constate la variation de la pression atmosphÃ©rique en ce point. DÃ¨s lors, il est facile de corrÃ©ler l'amplitude de la variation de la pression avec le niveau sonore entendu (ou mesurÃ©).

L'unitÃ© du systÃ¨me international de la pression est le **pascal** (**Pa**). Or, il est trÃ¨s rare de parler de la pression acoustique en pascal, car la variation de cette pression exprimÃ©e en pascal ne correspond pas Ã  ce que nous percevons. En d'autres termes, si la pression acoustique exprimÃ©e en pascal double, nous ne percevons pas un son deux fois plus fort.

Notre oreille fonctionne de faÃ§on logarithmique, et non linÃ©airement, face Ã  une variation de pression acoustique. C'est pour cela que l'on parle gÃ©nÃ©ralement de **niveau de pression acoustique**, oÃ¹ **SPL** (pour Sound Pressure Level en anglais), qui s'exprimera en **dÃ©cibel**. La relation entre la variation de pression et le niveau de pression acoustique se fait grÃ¢ce Ã  la relation :

$$L_p = 20\,\log_{10}\Big(\frac{p_{eff}}{p_{ref}}\Big) \qquad p_{ref} = 20\mu Pa$$

> ğŸ’¡ Si la pression acoustique double, on observe une augmentation du niveau sonore de 3 dB SPL. Lorsqu'on ressent un doublement du niveau sonore, on observe une augmentation de 10 dB.

La question se complexifie lorsque l'on rajoute la dimension frÃ©quentielle Ã  la question de la perception du niveau sonore.  En effet, nous percevons des niveaux sonores diffÃ©rents pour diffÃ©rentes frÃ©quences pourtant Ã©mises au mÃªme niveau de pression acoustique. Pour inclure cette dÃ©pendance frÃ©quentielle, nous avons mis en place une unitÃ© de mesure : la **sonie** ou **bruyance** (**loudness** en anglais). Il est donc possible ensuite de dÃ©finir des courbes d'**isosonie**, c'est-Ã -dire des courbes indiquant un niveau sonore de perception Ã©gale en fonction de la frÃ©quence et du niveau de pression acoustique.

```{r, echo = FALSE, fig.align="center", fig.cap = "Courbes d'isosonie, aussi dites de Fletcher-Munson"}
knitr::include_graphics(path = "_resources/diagrams/Courbes_isosonie.png")
```

Que conclure de cet abaque ?

+ Notre oreille ne perÃ§oit pas les frÃ©quences de maniÃ¨re Ã©gale.
+ Notre zone de sensibilitÃ© maximale se situe dans l'aigu (3k-4k Hz).
+ Notre perception d'un matÃ©riau sonore en fonction du niveau auquel nous l'Ã©coutons !

### Positionnement dans l'espace

Notre systÃ¨me auditif nous permet de situer l'Ã©mission d'un son dans l'espace. Cette capacitÃ© de localisation repose sur un ensemble de facteurs Ã©troitement liÃ©s entre eux.

On qualifie notre Ã©coute de **binaurale**, littÃ©ralement, Ã©couter avec deux oreilles. La prÃ©sence de deux "capteurs de pression" (oserait-on parler de microphones ?) sur les faces latÃ©rales de notre crÃ¢ne et un premier Ã©lÃ©ment expliquant notre capacitÃ© de localisation du son.

En effet, l'espacement de nos oreilles (en moyenne 15 cm), crÃ©er un dÃ©calage temporel entre nos deux canaux d'Ã©coutes. Ce lÃ©ger retard entendu d'un cÃ´tÃ© ou de l'autre nous permettra de placer un son plutÃ´t Ã  gauche ou plutÃ´t Ã  notre droite. On appelle cet Ã©cart de temps **diffÃ©rence de temps interaural**, ou **ITD** (interaural time difference en anglais) et se note $\Delta t$.

On pourrait d'ailleurs, grÃ¢ce aux formules de ce dÃ©but de chapitre, calculer le retard maximal moyen entre nos deux oreilles.

$$\Delta t_{max} = \frac d c = \frac {0,15}{340} = 0.4 \> ms$$

```{r, echo = FALSE, fig.align="center", fig.cap = "Illustration de l'ITD"}
knitr::include_graphics(path = "_resources/drawings/delta_t.svg")
```

Si nos oreilles sont espacÃ©es de quelques centimÃ¨tres, notre tÃªte les sÃ©parant reprÃ©sente un obstacle acoustique non nÃ©gligeable. De plus, les pavillons des oreilles imposent Ã©galement une certaine directivitÃ© Ã  notre Ã©coute. En premiÃ¨re approximation, on pourra donc considÃ©rer que l'ensemble formÃ© par la tÃªte et les pavillons implique une attÃ©nuation linÃ©aire des ondes sonores, elle-mÃªme fonction de l'angle d'incidence. On appelle cette diffÃ©rence de niveau **diffÃ©rence d'intensitÃ© interaural**, ou **ILD** (interaural level difference) et se note $\Delta i$. On considÃ¨re que si la diffÃ©rence de niveau de pression acoustique entre les deux oreilles est supÃ©rieure Ã  20 dB, on entendra l'Ã©vÃ¨nement sonore complÃ¨tement latÃ©ralisÃ©.

> ğŸ’¡ L'ombre acoustique que reprÃ©sentent la tÃªte et le pavillon n'est en rÃ©alitÃ© pas du tout linÃ©aire en frÃ©quence. La modification du timbre induite par ce systÃ¨me n'est pas perÃ§ue par notre cerveau comme une information de couleur, mais bien comme une information de spatialisation. Ainsi, selon l'angle d'incidence de l'Ã©vÃ¨nement sonore, son spectre sera filtrÃ© d'une certaine maniÃ¨re qui permettra Ã  notre cerveau de le positionner dans l'espace. La rÃ©ponse en frÃ©quence d'une tÃªte se nomme **HRTF** (**Head Related Transfer Function**).

Enfin, nous sommes Ã©galement capables de dÃ©terminer la distance d'un Ã©vÃ¨nement sonore. La plupart des paramÃ¨tres permettant d'Ã©valuer cette distance sont relatifs. Cela signifie que l'Ã©vÃ¨nement doit Ãªtre comparÃ© Ã  un autre pour pouvoir le repositionner dans l'espace. On pourra alors comparer :

+ Leurs niveaux sonores : un Ã©vÃ¨nement sonore plus fort paraÃ®t plus proche
+ Leurs timbres : l'absorption de l'air aura pour effet de diminuer les frÃ©quences aiguÃ«s
+ La sensation de rÃ©verbÃ©ration associÃ©e : plus le signal de l'Ã©vÃ¨nement sonore semblera solliciter la rÃ©ponse acoustique du lieu, plus celui-ci semblera fort.
+ Le temps d'arrivÃ©e des premiÃ¨res rÃ©flexions : le son direct d'un Ã©vÃ¨nement sonore lointain arrivera quasi simultanÃ©ment avec ses premiÃ¨res rÃ©flexions. Le son direct d'un Ã©vÃ¨nement sonore proche arrivera avant ses premiÃ¨res rÃ©flexions.

Le chapitre suivant traitera des notions d'acoustique Ã©lÃ©mentaire ainsi que de la rÃ©verbÃ©ration.


<!--

TODO

### Liens entre vision et audition

-->

<!--chapter:end:01-qualifier_le_son.Rmd-->

# Acoustique des salles


Tout environnement, sollicitÃ© par un Ã©vÃ¨nement sonore, produit une rÃ©ponse acoustique. Cette rÃ©ponse acoustique est appelÃ©e rÃ©verbÃ©ration. Elle est caractÃ©ristique dâ€™un lieu et peut, dans certains cas, Ãªtre une alliÃ©e prÃ©cieuse dans notre travail. Dans dâ€™autres, elle est source de problÃ¨mes et complexifie grandement notre travail dâ€™Ã©coute analytique.

## GÃ©nÃ©ralitÃ©s

### La rÃ©verbÃ©ration

L'acoustique d'une salle est gÃ©nÃ©ralement dÃ©crite en deux temps : le temps des premiÃ¨res rÃ©flexions et le temps du champ diffus.

```{r, echo = FALSE, fig.align='center', fig.cap = "SchÃ©ma d'une rÃ©ponse impulsionnelle de rÃ©verbÃ©ration."}
knitr::include_graphics(rep("_resources/drawings/reverb.svg"))
```

Les premiÃ¨res rÃ©flexions sont les premiers rebonds dâ€™une onde sonore sur les parois dâ€™une salle et sont caractÃ©ristiques de la signature acoustique du lieu. Ces rebonds reviennent Ã  lâ€™auditeur avec un certain temps. Ce retard se nomme souvent Â«Â prÃ©-dÃ©laiÂ Â» dans les moteurs de rÃ©verbÃ©ration artificiels. Ce prÃ©dÃ©lai est fonction de deux paramÃ¨tresÂ :

+ la taille de la piÃ¨ceÂ ; plus la piÃ¨ce est petite, plus les premiÃ¨res rÃ©flexions reviendront Ã  lâ€™auditeur rapidement.
+ les positions de la source sonore et de lâ€™auditeurÂ ; plus lâ€™auditeur est proche de la source, plus les premiÃ¨res rÃ©flexions arriveront aprÃ¨s le son direct, plus lâ€™auditeur est loin de la source, plus les premiÃ¨res rÃ©flexions arriveront en mÃªme temps que le son direct.

Lorsque les premiÃ¨res rÃ©flexions elles-mÃªmes auront rebondi plusieurs fois sur les parois du lieu, le phÃ©nomÃ¨ne dâ€™Ã©cho des premiÃ¨res rÃ©flexions va se muer en champs diffus, par nature plus dense. La longueur du champ diffus se mesure grÃ¢ce au RT60. Cette mÃ©thode de mesure propose de regarder le temps que met la rÃ©verbÃ©ration Ã  perdre 60Â dB. Ce temps permettra ensuite de donner une longueur de rÃ©verbÃ©ration.

### Calcul du temps de rÃ©verbÃ©ration

L'Ã©quation de Sabine permet de calculer le temps de rÃ©verbÃ©ration d'une salle Ã  partir de son volume et du coefficient d'absorption de ses matÃ©riaux.

$$RT_{60} = 0.1611 \times \frac{V}{\sum_{i=0}^{k} S_i.\alpha_i}$$

$V$ s'exprime en $m^3$ et $S$ en $m^2$. $\alpha$ est le coefficient d'absorption du matÃ©riau, en sabins. Ce coefficient est compris entre 0 et 1, plus il est important plus le matÃ©riau est absorbant.

En guise d'exemple sur l'utilisation de la formule ci-dessus, prenons le cas d'une piÃ¨ce de $25\,m^2$ ($5\,m$ par $5\,m$) et de $2.40\,m$ de hauteur. Nous considÃ©rons que le sol est en parquet et les murs en plÃ¢tre. Nous avons donc $25\,m^2$ de parquet et $4\times(5\times2.4)=48\,m^2$. On trouve sur les sites de fabricant de matÃ©riaux que le plÃ¢tre peint a un coefficient d'absorption de 0.05 sabins et le bois un coefficient de 0.15 sabins. Notre calcul final.

$$RT_{60} = 0.1611 \times \frac{25 \times 2.4}{25\times0.15+48\times0.05} \approx 1.57\,s$$

On peut dÃ¨s lors calculer la **distance critique**, distance Ã  partir de laquelle on entendra autant un Ã©vÃ¨nement sonore que la rÃ©ponse acoustique de la salle Ã  son stimulus.

$$d_c \approx 0.057 \times \sqrt{\frac{V}{RT60}}$$

Dans notre exemple $d_c \approx 0.35\,m$.

Il est souvent considÃ©rÃ© que la taille de la piÃ¨ce joue un rÃ´le dÃ©terminant sur la longueur de rÃ©verbÃ©ration. L'Ã©quation de Sabine indique bien que le coefficient d'absorption des matÃ©riaux y joue un rÃ´le beaucoup plus important. Le modÃ¨le de rÃ©verbÃ©ration de l'IRCAM va jusqu'Ã  complÃ¨tement dÃ©corrÃ©ler la taille de la piÃ¨ce simulÃ©e du temps de rÃ©verbÃ©ration. Au final, la taille de l'espace joue davantage sur la structure temporelle des Ã©chos, et donc, principalement sur les premiÃ¨res rÃ©flexions.

### Limite de l'Ã©quation de Sabine

Il convient d'observer plusieurs rÃ©serves quant Ã  l'utilisation de l'Ã©quation de Sabine. PremiÃ¨rement, elle ne tient pas compte de l'aspect frÃ©quentiel liÃ© Ã  l'absorption des matÃ©riaux. En effet, le temps de rÃ©verbÃ©ration des graves est presque toujours plus long que celui des aigus. Afin de contourner ce problÃ¨me, on pourra chercher des coefficients d'absorption tenant compte de la frÃ©quence et ainsi rÃ©soudre l'Ã©quation de Sabine pour certaines plages frÃ©quentielles.

L'Ã©quation de Sabine pose Ã©galement problÃ¨me pour de petits espaces (rÃ©gie d'Ã©coute par exemple) en prÃ©disant un temps de rÃ©verbÃ©ration trop long. Dans ce cas, l'Ã©quation d'Eyring est plus adaptÃ©e.

$$RT_{60} = -0.1611 \times \frac{V}{\sum_{i=0}^{k} S_i.\ln(1-\alpha_i)}$$

> ğŸ’¡ l'Ã©quation d'Eyring n'amÃ©liore pas non plus la problÃ©matique frÃ©quentielle.

### Le phÃ©nomÃ¨ne d'onde stationnaire

La plupart des piÃ¨ces de vie sont des salles rectangulaires. Dans ce cas, les surfaces sont toutes parallÃ¨les. Ce type de salle est particuliÃ¨rement propice Ã  l'apparition d'ondes stationnaires. Une onde stationnaire est un phÃ©nomÃ¨ne acoustique provoquant l'augmentation de volume de certaines frÃ©quences (ventre) et la disparition d'autres (nÅ“uds).

Nous aborderons ici ce  phÃ©nomÃ¨ne sous l'angle de l'acoustique des salles, mais il est applicable dans d'autres situations, comme la vibration d'une corde par exemple.

```{r, echo = FALSE, fig.align='center', fig.cap = 'Les points rouges reprÃ©sente les noeuds, les amplitudes maximales sont les ventres. Infographie par Lucas Vieira'}
knitr::include_graphics(rep("https://upload.wikimedia.org/wikipedia/commons/7/7d/Standing_wave_2.gif"))
```

Il est possible de calculer les frÃ©quences d'un mode grÃ¢ce aux formules vues au chapitre prÃ©cÃ©dent :

$$f(n) = \frac{c}{2L}.n$$
oÃ¹ $c=340\,m.s^{-1}$, $L$ est la longueur considÃ©rÃ©e de la piÃ¨ce. Pour $n=1$ on trouve le **mode propre**. Pour $n>1$ on trouvera tous les **modes harmoniques**.

Ã‰tudions la frÃ©quence du mode propre pour deux cas thÃ©oriques : une salle de 16 mÂ² (4x4) et une autre de 49 mÂ² (7x7). On trouvera donc :

$$f(1)_{L=4m} = 42.5 \,Hz \>\>\>\> f(1)_{L=7m} = 24 \,Hz$$

On en dÃ©duit donc que, plus la piÃ¨ce est grande, plus la frÃ©quence des modes propres sera grave. Il convient Ã©galement de considÃ©rer la distance de chaque surface parallÃ¨le, car les piÃ¨ces sont rarement cubiques. Cela implique donc la prÃ©sence de trois modes propres, plus leurs modes harmoniques, pour une seule et mÃªme salle.

## PremiÃ¨res rÃ©flexions et filtre en peigne

Nous avons vu que la rÃ©ponse acoustique, ou rÃ©verbÃ©ration, d'une salle se dÃ©compose gÃ©nÃ©ralement en deux parties, la premiÃ¨re Ã©tant les premiÃ¨res rÃ©flexions. Ces premiÃ¨res rÃ©flexions sont donc, comme leur nom l'indique, les premiers rebonds que nous entendons suite Ã  un Ã©vÃ¨nement sonore.

Dans de petites piÃ¨ces, les premiÃ¨res rÃ©flexions peuvent Ãªtre entendues si proche du son direct que cela gÃ©nÃ¨re un type de filtrage bien particulier appelÃ© **filtre en peigne**.

```{python, echo=FALSE, fig.align="center", fig.caption="Filtre en peigne correspondant Ã  un retard d'une milliseconde"}
import matplotlib.pyplot as plt
import numpy as np

fs = 48000  # Sample rate
T = 1/fs    # Sample period
L = 48    # Delay
a = 1     # Attenuation factor

# h[n] = dirac[n] + a * dirac[n-L]
h = np.zeros(fs)
h[0] = 1
h[L] = a

# Transfer function H via FFT - same # of bins
H_FFT = 20*np.log10(np.fft.fft(h, fs))

plt.figure()
var = plt.xlim(20,20000)
var = plt.ylim(-94,24)
var = 0
plt.xscale("log")
plt.xlabel("Frequences (Hz)")
plt.ylabel("Amplitude (dB)")
plt.title("Filtre en peigne correspondant Ã  un retard d'une milliseconde")
plt.plot(H_FFT)
```

Toujours en utilisant les formules dÃ©finies au premier chapitre, on Ã©tablit la relation suivante :

$$ fc = \frac 1{2t} = \frac c{2d} $$

OÃ¹ $fc$ correspond Ã  la frÃ©quence d'annulation la plus grave du filtre en peigne. Les autres frÃ©quences se calculent grÃ¢ce Ã  la relation $f(n) = fc*n$. Le phÃ©nomÃ¨ne de filtre en peigne est donc Ã©galement harmonique.

Ainsi, on peut calculer les filtres en peignes prÃ©sents au point d'Ã©coute d'une rÃ©gie de mixage ou de prise de son grÃ¢ce Ã  la mesure du chemin des premiÃ¨res rÃ©flexions.

```{r, echo = FALSE, fig.align='center', fig.cap = "Ensemble des premiÃ¨res reflexions entendues par une oreille pour une enceinte (hors plafond et plancher/bureau)."}
knitr::include_graphics(rep("_resources/drawings/roomPr.svg"))
```

> ğŸ’¡ La rÃ©flexion du son sur une paroi est tout Ã  fait comparable Ã  de l'optique gÃ©omÃ©trique. Une onde sonore arrivant avec un angle d'incidence $\alpha$ sur une surface sera rÃ©flÃ©chie avec le mÃªme angle. Ainsi, il est souvent conseillÃ© d'utiliser un miroir lorsque l'on positionne des traitements acoustiques. Lorsque la personne assise au point d'Ã©coute voit une enceinte dans un miroir placÃ© sur un mur, on sait alors qu'il faudra placer le panneau Ã  la place du miroir.

On se rend donc compte que l'influence des filtres en peigne gÃ©nÃ©rÃ©s par les premiÃ¨res rÃ©flexions est trÃ¨s importante. Ce phÃ©nomÃ¨ne Ã  lui seul explique l'intÃ©rÃªt d'une grande rÃ©gie d'Ã©coute. En effet, plus une piÃ¨ce est grande, plus l'Ã©cart de temps entre le son direct et les premiÃ¨res rÃ©flexions est important. Cela implique deux choses :

+ Notre cerveau favorisera le son direct plus facilement (effet de prÃ©cÃ©dence)
+ Ã€ partir d'une certaine taille, l'effet du filtre en peigne se mue en information d'acoustique pour notre cerveau. Au-delÃ  de 40 ms (trajet d'une premiÃ¨re rÃ©flexion d'environ 14 m), l'Ã©cart entre le son direct et les premiÃ¨res rÃ©flexions est tel que nous entendons un Ã©cho (effet Haas). 

Afin de rÃ©duire au maximum les effets des filtres en peignes, il est recommandÃ© de placer des traitements aux points de rÃ©flexion critique par rapport Ã  la position d'Ã©coute (voir schÃ©ma ci-dessus).

```{python, echo=FALSE, fig.align="center", fig.caption="Filtre en peigne correspondant Ã  un retard d'une milliseconde"}
import matplotlib.pyplot as plt
import numpy as np

fs = 48000  # Sample rate
T = 1/fs    # Sample period
L = 48    # Delay
a = 0.22     # Attenuation factor

# h[n] = dirac[n] + a * dirac[n-L]
h = np.zeros(fs)
h[0] = 1
h[L] = a

# Transfer function H via FFT - same # of bins
H_FFT = 20*np.log10(np.fft.fft(h, fs))

plt.figure()
var = plt.xlim(20,20000)
var = plt.ylim(-144,24)
var = 0
plt.xscale("log")
plt.xlabel("Frequences (Hz)")
plt.ylabel("Amplitude (dB)")
plt.title("MÃªme filtre en peigne, avec une attÃ©nuation de 20 dB sur la reflexion")
plt.plot(H_FFT)
```


## Traitement acoustique

GrÃ¢ce aux diffÃ©rents points abordÃ©s ci-dessus, nous avons maintenant bien l'idÃ©e que lâ€™acoustique dâ€™un lieu est un des facteurs les plus dÃ©terminants sur le rendu sonore. Mais câ€™est aussi celui sur lequel il est plus difficile et technique dâ€™intervenir.

On favorisera au maximum une architecture optimisÃ©e pour l'acoustique. Dans ce but, il convient de n'avoir aucune surface parallÃ¨le, cela permettant de grandement limiter l'apparition d'ondes stationnaires. On choisira Ã©galement des matÃ©riaux avec des propriÃ©tÃ©s acoustiques intÃ©ressantes (plÃ¢tre et carrelage sont Ã  proscrire, au profit du bois par exemple).

On se posera ensuite la question des endroits de la piÃ¨ce les plus propices pour y positionner un Ã©vÃ¨nement sonore (enceinte, musicien, etc.). On cherchera donc un point oÃ¹ la contribution des diffÃ©rents modes semble Ã©quilibrÃ©e. Pour cela, il suffit de se munir d'une enceinte et d'y diffuser une musique ou un signal test qui nous est familier. En dÃ©plaÃ§ant l'enceinte, on pourra Ã©valuer la contribution acoustique de la piÃ¨ce en diffÃ©rents points.

Une fois ces considÃ©rations prises en compte, on pourra alors aborder le traitement de l'acoustique.

> ğŸ›‘ Il ne faut pas confondre isolation acoustique et traitement acoustique. Dans le premier cas, on chercher a limiter la contribution sonore d'un lieu sur son environnement, dans l'autre on cherche Ã  amÃ©liorer la propagation du son dans un espace donnÃ©. Une isolation acoustique satisfaisante nÃ©cessite de lourds travaux, voire l'amÃ©nagement d'une "boÃ®te dans une boÃ®te". Ces notions d'acoustiques dÃ©passent le cadre de ce cours. 

### Les types de traitements

On trouve, en gÃ©nÃ©ral, deux types de traitementsÂ :

+ Les absorbeurs, qui rÃ©duisent lâ€™Ã©nergie dâ€™une onde sonore Ã  son impact.
+ Les diffuseurs, qui rÃ©partissent lâ€™Ã©nergie dâ€™une onde sonore dans lâ€™espace.

Dans un lieu oÃ¹ la quantitÃ© de rÃ©verbÃ©ration est jugÃ©e trop importante, on utilisera des absorbeurs. Ã€ lâ€™inverse, dans un lieu oÃ¹ lâ€™on souhaite prÃ©server la quantitÃ© de rÃ©verbÃ©ration, mais en Ã©vitant les phÃ©nomÃ¨nes de modes ou de filtre en peignes, on utilisera des diffuseurs.

Dans de petits lieux, lâ€™usage de diffuseur semble contre-productif, la prioritÃ© Ã©tant dâ€™absorber au maximum les premiÃ¨res rÃ©flexions, celle-ci arrivant trÃ¨s rapidement aprÃ¨s lâ€™Ã©mission du son direct.

### ConsidÃ©ration dâ€™acoustique pour le travail de son

Il est vivement recommandÃ© dâ€™installer un studio, de prise de son ou de monitoring, dans un lieu plutÃ´t grand. En effet, plus le lieu est grand, plus il sera facile de positionner un point de prise de son ou dâ€™Ã©coute suffisamment Ã©loignÃ© des parois afin de minimiser lâ€™influence des premiÃ¨res rÃ©flexions. Aussi, plus le lieu est grand, plus lâ€™espace y sera suffisant pour installer des traitements acoustiques. Certains types de traitements, comme les basstraps, peuvent prendre une place bien trop importante pour Ãªtre installÃ©e dans des piÃ¨ces de dimension habituelle (chambres, bureau, etc.). On se rappellera aussi de choisir une piÃ¨ce de travail avec le minimum de surface parallÃ¨le, afin de limiter les ondes stationnaires.

En ce qui concerne les traitements en eux-mÃªmes, il est vivement recommandÃ© de traiter en prioritÃ© le bas du spectre. Lâ€™ajout de basstrap est donc prioritaire sur le reste des traitements. Plus la longueur dâ€™onde Ã  traiter est grande (donc la frÃ©quence grave), plus la taille des matÃ©riaux devra Ãªtre importante. On retrouve donc le point abordÃ© prÃ©cÃ©demmentÂ : traiter une piÃ¨ce correctement, demande un certain espace. Par ailleurs, il est important que les traitements appliquÃ©s Ã  un lieu soient linÃ©aires en frÃ©quence, câ€™est-Ã -dire quâ€™il ne se concentre pas sur une seule zone du spectre. Cela arrive souvent avec les kits de mousses peu onÃ©reux, mais nâ€™ayant une rÃ©elle efficacitÃ© que dans les mÃ©diums et hautes frÃ©quences.

Pour une rÃ©gie d'Ã©coute, on sera tentÃ© de privilÃ©gier des traitements d'absorption. En effet, une rÃ©verbÃ©ration trop longue dans une rÃ©gie de monitoring risque fort de fausser certaines prises de dÃ©cisions (distance des microphones Ã  la source, quantitÃ© de rÃ©verbÃ©ration, etc.). Ã€ l'inverse, une piÃ¨ce avec un temps de rÃ©verbÃ©ration trop court pourra crÃ©er un sentiment d'inconfort, voire de malaise.

Pour une salle de prise de son, l'idÃ©al est de disposer d'un grand espace avec un traitement acoustique principalement basÃ© sur de la diffusion, pour ensuite disposer de traitements absorbants amovibles permettant de sculpter le rendu acoustique en fonction de la prise de son Ã  rÃ©aliser. Pour des petits lieux (- de 25 mÂ²), on cherchera Ã  absorber au maximum afin de limiter les effets de filtre en peigne.

<!--chapter:end:02-l_acoustique_des_salles.Rmd-->

# Le chemin du signal

La premiÃ¨re mission d'un preneur de son est de s'assurer de l'arriver Ã  bon port des signaux dans l'enregistreur. En effet, toute notion de mise en scÃ¨ne sonore et d'esthÃ©tique devient trÃ¨s secondaire si le contenu n'a pas Ã©tÃ© enregistrÃ©.

Le diagramme ci-dessous reprend les principaux Ã©tages rencontrÃ© par un signal audio dans un context de production numÃ©rique. Il est essentiel d'Ãªtre le plus famillier possible avec ces diffÃ©rents composants.

```{r, echo=FALSE, out.width="100%", fig.cap = "Le chemin du signal"}
knitr::include_graphics(path = "_resources/diagrams/cheminSignal.drawio.svg")
```

> Le schÃ©ma peut-Ãªtre agrandi en ouvrant l'image dans un nouvel onglet.

Chaque Ã©lÃ©ment sera abordÃ© dans des sections dÃ©diÃ©s dans la suite de ce livre.

<!--chapter:end:03-le_chemin_du_signal.Rmd-->

# Les microphones

Un microphone est un **transducteur**, qui permet de transformer une onde acoustique en onde Ã©lectrique. Il est constituÃ© dâ€™une membrane et dâ€™une Ã©lectronique associÃ©e permettant de prÃ©parer le signal captÃ© Ã  Ãªtre transmis Ã  la suite de la chaÃ®ne audio Ã  travers un cÃ¢ble. La connectique standard des microphones est le XLR. Il sâ€™agit de connectique **asymÃ©trique.**

## Les technologies de microphones

Beaucoup de procÃ©dÃ©s ont pu Ãªtre utilisÃ©s pour permettre la captation du son. Nous aborderons ici les plus communesÂ :

+ Les microphones Ã©lectrostatiques/Ã  condensateur
+ Les microphones Ã  ruban
+ Les microphones dynamiques

### Les microphones Ã©lectrostatiques/Ã  condensateur

Ce sont, historiquement, les premiers microphones Ã  permettre une captation satisfaisante du son (rÃ©ponse en frÃ©quence). Mais Ã  leurs dÃ©buts, ils sont trÃ¨s sensibles aux conditions de tempÃ©rature et dâ€™humiditÃ©. Ces problÃ¨mes nâ€™ont plus cours aujourdâ€™hui. Leur fonctionnement repose sur lâ€™utilisation dâ€™un condensateur en guise de capsule. Lorsque le son rencontre celle-critique, lâ€™onde dÃ©forme les armatures du condensateur et gÃ©nÃ¨re donc une variation de tension. De par lâ€™utilisation de ce condensateur, ces microphones nÃ©cessitent une alimentation externe (dites fantÃ´me), maintenant standardisÃ©e Ã  +48V.

Ces microphones possÃ¨dent des rÃ©ponses en frÃ©quence souvent trÃ¨s linÃ©aire et une excellente rÃ©ponse en transitoire. Leur niveau de sortie (sensibilitÃ©) est Ã©levÃ©. Leur impÃ©dance de sortie est basse.

ExemplesÂ : NeumannÂ U87/AKG C414/ShoepsÂ CMC4/DPA 4041

### Les microphones Ã  ruban

+ PrÃ©fÃ©rÃ© Ã  leurs homologues statiques au dÃ©but du siÃ¨cle.
+ Fonctionne grÃ¢ce Ã  une feuille en mÃ©tal, attachÃ©e entre deux aimants. Lâ€™onde sonore fait vibrer le ruban, perturbant ainsi le champ Ã©lectromagnÃ©tique des aimants et gÃ©nÃ©rant donc une variation de tension.
+ Attention au 48Â volts des alimentations fantÃ´me, elles peuvent mettre lâ€™Ã©lectronique de ces microphones hors service.
+ Souvent, ces microphones flattent le grave et attÃ©nuent les aiguÃ«s. Leurs rÃ©ponses en transitoire sont Ã©galement assez douces.
+ Leur niveau de sortie est faible.
+ Leur impÃ©dance de sortie est Ã©levÃ©e.

ExemplesÂ : Royer R121/Cohles/Beyerdynamic M160

### Les microphones dynamiques

+ Ces microphones sont conÃ§us pour des conditions dâ€™utilisation rudesÂ : scÃ¨ne, fort niveau de pression sonore, etc.
+ Ils sont mÃ©caniquement et Ã©lectroniquement robustes.
+ Leurs membranes sont rattachÃ©es Ã  aimant, lui-mÃªme entourÃ© dâ€™une bobine. Lorsque cette premiÃ¨re est mise en vibration par une onde sonore, le dÃ©placement de lâ€™aimant Ã  lâ€™intÃ©rieur de la bobine permet de crÃ©er une variation de tension Ã©lectrique.
+ Leur rÃ©ponse en frÃ©quence est souvent accidentÃ©e, et donc, loin dâ€™Ãªtre linÃ©aire. Cela peut Ãªtre vu comme un inconvÃ©nient ou comme un outil de Â«Â colorationÂ Â» du son.
+ Leur niveau de sortie est faible.
+ Leur impÃ©dance de sortie est Ã©levÃ©e.

ExemplesÂ : ShureÂ SM57/ElectrovoiceÂ RE20/SennheiserÂ MD441

## La directivitÃ©

La directivitÃ© dâ€™un microphone permet de dÃ©crire sa capacitÃ© Ã  rÃ©aliser une Â«Â Ã©couteÂ Â» sÃ©lective des ondes sonores Ã©mises dans un espace.

+ Un microphone omnidirectionnel capte le son tout autour de lui.
+ Un microphone cardioÃ¯de capte le son devant lui et le rejette Ã  lâ€™arriÃ¨re.
+ Un microphone bidirectionnel capte trÃ¨s sÃ©lectivement devant lui et derriÃ¨re lui.

Voir la fiche sur les directivitÃ©s.

## La taille des membranes

La taille des membranes influe sur la captation du son. Plus la capsule est grande, plus les frÃ©quences aiguÃ«s seront diffractÃ©es et donc attÃ©nuÃ©es dans le signal gÃ©nÃ©rÃ©.
Un microphone Ã  petite membrane est donc techniquement un microphone plus Â«Â justeÂ Â». Cependant, lâ€™emploi de large membrane permet aussi dâ€™adoucir lâ€™aiguÃ« trop important de certaines sources. Câ€™est un choix de couleur.

<!--chapter:end:04-les_microphones.Rmd-->

# La directivitÃ© des microphones

Comme dÃ©cris dans le chapitre sur les microphones, sa directivitÃ© rend compte de sa capacitÃ© Ã  sÃ©lectionner, ou pas, son champ de captation. On connaÃ®t trois grandes directivitÃ©s :

+ Omnidirectionnel : qui capte lâ€™ensemble du champ sonore de faÃ§on indiffÃ©renciÃ©e
+ CardioÃ¯de : qui capte Ã  lâ€™avant, mais rejette Ã  lâ€™arriÃ¨re du microphone
+ Bidirectionnel : qui capte Ã  lâ€™avant et Ã  lâ€™arriÃ¨re, mais selon un lobe plus resserrÃ© quâ€™en cardioÃ¯de.

Dans ce chapitre, nous tÃ¢cherons dâ€™Ã©tudier les diffÃ©rentes directivitÃ©s de microphones et leur influence sur une prise de son.

## Capsules Ã  pression

Lorsque lâ€™on Ã©tudie un microphone, il est peut-Ãªtre plus judicieux de revenir Ã  son Ã©lÃ©ment fondamental : la capsule. Il existe deux familles de capsules, celles dites Â«Â Ã  pressionÂ Â», et celles dites Ã  la Â«Â gradient de pressionÂ Â».

Une capsule sensible Ã  la pression est omnidirectionnelle, puisquâ€™elle capte lâ€™ensemble du champ acoustique. MathÃ©matiquement, cette relation sâ€™exprime, en coordonnÃ©es polaires, par :

$$ \theta = 1 $$

Il faut ici comprendre que lâ€™angle dâ€™incidence dâ€™un son par rapport au microphone importe peu, ce dernier nâ€™attÃ©nuera jamais le signal.

## Capsules Ã  gradient de pression

Une capsule Ã  gradient de pression est sensible Ã  la **variation** du champ de pression. Ces capsules ne sont plus omnidirectionnelles, mais bidirectionnelles : elles captent devant et derriÃ¨re elles. MathÃ©matiquement, une telle directivitÃ© sâ€™exprime par la relation (en coordonnÃ©es polaires) :

$$ \theta = cos(\alpha) $$

OÃ¹ $\alpha$ est lâ€™angle dâ€™incidence dâ€™un son par rapport Ã  la capsule.

## Et les autres directivitÃ©s ?

Il est possible, Ã  partir des deux Ã©quations ci-dessus, de retrouver toutes les autres directivitÃ©s. Par exemple, un microphone cardioÃ¯de a une Ã©quation de directivitÃ© polaire tel que :

$$ \theta = \frac{1}{2}(1 + cos(\alpha)) $$

Cela nous indique donc quâ€™une des faÃ§ons de concevoir un microphone a directivitÃ© variable est dâ€™utiliser deux capsules dont on pourra changer le rapport de gain. Cependant, la plupart des microphones cardioÃ¯des ne possÃ¨dent quâ€™une seule capsule. La directivitÃ© est alors crÃ©Ã©e par un systÃ¨me de labyrinthe acoustique dans le corps de microphone.

<!-- <iframe scrolling="no" title="DirectivitÃ© Microphone" src="https://www.geogebra.org/material/iframe/id/t4acpbvb/width/530/height/530/border/888888/sfsb/true/smb/false/stb/false/stbh/false/ai/false/asb/false/sri/false/rc/false/ld/false/sdz/false/ctl/false" width="530px" height="530px" style="border:0px;"> </iframe> -->

## DirectivitÃ©s rÃ©elles

```{r, echo = FALSE, fig.cap = "DirectivitÃ© rÃ©elle d'un microphone cardioÃ¯de (Sennheiser)", out.width='50%', fig.align='center'}
knitr::include_graphics(rep("http://electroacoustique.univ-lemans.fr/cours/Grain1.2en/res/image_15.jpg"))
```

<!--chapter:end:05-la_directivitÃ©_des_microphones.Rmd-->

# Les cÃ¢bles

Les cÃ¢bles assurent un rÃ´le de transport vis-Ã -vis de signaux Ã©lectriques. Ces signaux peuvent reprÃ©senter une onde sonore (prÃ©cÃ©demment captÃ©e par un microphone), une valeur de contrÃ´le pour piloter un appareil (pÃ©dale dâ€™expression) ou encore une information numÃ©rique (cÃ¢ble USB, ethernet, etc.).

En audio, il existe principalement deux types de cÃ¢blesÂ :

+ Les cÃ¢bles Ã  modulation unique (un signal transportÃ©)
+ Les cÃ¢bles Ã  double modulation (deux signaux transportÃ©s)

## CÃ¢ble Ã  modulation unique

Ils sont constituÃ©s de quatre Ã  cinq composantsÂ :
+ dâ€™un cÅ“ur composÃ© dâ€™un filament (souvent multibrin) en un mÃ©tal conducteur, vÃ©hiculant le signal Ã©lectrique.
+ d'une gaine isolante (plastique) protÃ©geant le cÅ“ur
+ d'une tresse en cuivre connectÃ©e Ã  la masse
+ Parfois, d'une feuille de cuivre, enrobant la tresse, permettant de rÃ©aliser une cage de faraday et de protÃ©ger le cÅ“ur des ondes Ã©lectromagnÃ©tiques.
+ Enfin, d'une derniÃ¨re gaine isolante, permettant de protÃ©ger l'ensemble du cÃ¢ble.

Ces cÃ¢bles sont communÃ©ment soudÃ©s Ã  des fiches Jack TS, ou RCA. Ils sont communÃ©ment utilisÃ©s pour les instruments des musiques ainsi que pour l'audio grand public.

## CÃ¢ble Ã  double modulation

La structure de ces cÃ¢bles est identique aux cÃ¢bles Ã  modulation unique, Ã  la prÃ©sence prÃ¨s d'un deuxiÃ¨me cÅ“ur, permettant de transporter un deuxiÃ¨me signal Ã©lectrique.

Ces cÃ¢bles sont souvent soudÃ©s Ã  des fiches XLR, Jack TRS, Jack Battam, Â«Â mini-jackÂ Â», etc.

## Les connexions asymÃ©triques

Les connexions asymÃ©triques permettent de transporter un signal entre une source et un rÃ©cepteur. Il s'agit de la faÃ§on la plus simple de connecter deux appareils devant Ã©changer des signaux. Cependant, sur de longue distance, le cÃ¢ble peut se comporter comme une antenne et induire sur le signal certaines ondes Ã©lectromagnÃ©tiques (comme la radio). Ces connexions utilisent des cÃ¢bles Ã  modulation unique.

## Les connexions symÃ©triques

Le but de ces connexions est de palier au problÃ¨me des connexions asymÃ©trique. Dans l'appareil Ã©metteur, le signal Ã  transporter est dupliquÃ©, et ce duplicata est inversÃ© en phase. Cette Ã©tape s'appelle la symÃ©trisation. C'est deux signaux sont appelÃ©s point chaud (signal d'origine) et point froid (signal opposÃ© en phase). Le cÃ¢ble transporte ces deux signaux. Sur son trajet, lorsqu'une perturbation Ã©lectromagnÃ©tique est induite sur le signal, celle-ci s'inscrit en phase sur les deux signaux (point chaud et point froid). Ã€ l'arrivÃ©e, l'appareil rÃ©cepteur inverse la phase du point froid et le somme avec le point chaud. Cette Ã©tape se nomme la dÃ©-symÃ©trisation. Ainsi le signal d'origine est sommÃ© en phase, tandis que les interfÃ©rences sont sommÃ©es hors phase et s'annulent.
Les connexions symÃ©triques nÃ©cessitent un cÃ¢ble Ã  double modulation.

## Les connexions stÃ©rÃ©o asymÃ©triques

Ces connexions permettent de vÃ©hiculer deux signaux Ã  travers un seul et mÃªme cÃ¢ble. Elles nÃ©cessitent un cÃ¢ble Ã  double modulation.

## Les connexions d'insert

UtilisÃ©es dans les consoles afin de permettre l'insertion de pÃ©riphÃ©rique de traitement externe, ces connexions permettent d'envoyer le signal vers le pÃ©riphÃ©rique et de le rÃ©cupÃ©rer avec le mÃªme cÃ¢ble. Elles utilisent des cÃ¢bles Ã  double modulation.

<!--chapter:end:06-les_cables_analogiques.Rmd-->

# Les prÃ©amplificateurs de microphones

Le rÃ´le dâ€™un prÃ©ampli est de rÃ©aliser une amplification en tension du signal Ã©mis par un microphone. Cette opÃ©ration est indispensable pour permettre Ã  notre signal de traverser tout le reste de la chaÃ®ne du traitement audio.

## Les qualitÃ©s dâ€™un prÃ©ampli

+ La quantitÃ© dâ€™amplification. Plus lâ€™amplification disponible est grande, au plus le prÃ©ampli sera capable de rÃ©pondre Ã  des situations exigeantes, tel que lâ€™enregistrement dâ€™une source Ã  faible niveau avec un microphone Ã  faible sensibilitÃ©.
+ La rÃ©ponse en frÃ©quence. ThÃ©oriquement, celle-ci doit Ãªtre la plus neutre possible. Une certaine coloration peut Ãªtre acceptÃ©e (voire souhaitÃ©e), mais celle-ci doit rester raisonnable pour rÃ©pondre Ã  des critÃ¨res dâ€™utilisations professionnelles.
+ La rÃ©ponse en transitoire. Certains prÃ©amplis auront tendance Ã  adoucir la sensation dâ€™attaque des sources. Cet effet nâ€™est pas souhaitable.
+ Le rapport signal bruit. Nous cherchons toujours Ã  rajouter le moins de bruit possible sur le chemin de notre signal.

## Les technologies de prÃ©ampli

Il existe trois grandes faÃ§ons de construire un prÃ©amplificateurÂ :

+ Ã  tubes (ou lampes). Le tube est historiquement le premier composant Ã©lectronique permettant lâ€™amplification des signaux.
+ Ã  transistor. Lâ€™invention du transistor est sans doute la plus grande rÃ©volution technologique du siÃ¨cle dernier. Celui-ci permet de remplacer les lampes pour une taille bien plus petite et une bien meilleure fiabilitÃ©.
+ Ã  circuit intÃ©grÃ©. Les circuits intÃ©grÃ©s permettent Ã©galement lâ€™amplification de signaux.

Chacune de ces technologies offre de trÃ¨s lÃ©gÃ¨re variation de son lorsque les prÃ©amplis sont poussÃ©s dans leur retranchement. Cette couleur liÃ©e Ã  la technologie est toujours Ã  pondÃ©rer, car elle dÃ©pend grandement de la topologie du circuit. De plus, lâ€™impÃ©dance dâ€™entrÃ©e et de sortie du prÃ©ampli a sans doute dans bien des cas un rÃ´le bien plus important.

## Les contrÃ´les dâ€™un prÃ©ampli

Un prÃ©ampli propose souvent les rÃ©glages suivantsÂ :

+ Un potentiomÃ¨tre de gain (qui est souvent remplacÃ© par un sÃ©lecteur crantÃ©, plus prÃ©cis, pour les modÃ¨les haut de gamme).
+ Un bouton activant lâ€™alimentation fantÃ´me. En effet, câ€™est bien le prÃ©ampli qui gÃ©nÃ¨re cette tension dâ€™alimentation pour les microphones statiques.
+ Un bouton dâ€™inversion de phase.
+ Un coupe-bas.

<!--chapter:end:07-les_preamplificateurs.Rmd-->

# La conversion analogique numÃ©rique

## La nÃ©cessitÃ© de la conversion analogique numÃ©rique

Le support dâ€™enregistrement historique de la musique est la bande magnÃ©tique. Le dÃ©faut dâ€™un tel support de stockage est principalement son rapport signal/bruit, peu avantageux. A contrario, lâ€™enregistrement numÃ©rique offre une dynamique bien supÃ©rieure Ã  celle des supports analogiques.

Aujourdâ€™hui, la plupart des productions multimÃ©dias reposent sur lâ€™utilisation dâ€™ordinateurs en lieu et place des Ã©quipements analogiques Ã©quivalents. Cela reprÃ©sente pour les structures une Ã©conomie de coÃ»t importante pour peu ou pas de modification sur la qualitÃ© du contenu.

## D'un signal continu vers un signal Ã©chantillonnÃ©

La caractÃ©ristique principale d'un signal analogique est sa continuitÃ©. Un signal continu, en mathÃ©matique, se dÃ©finit par un signal dÃ©fini en n'importe quel instant. Afin d'Ãªtre numÃ©risÃ©, un tel signal doit Ãªtre dÃ©nombrÃ©. En effet, la notion d'infini imposÃ© par la continuitÃ© du signal n'a pas d'existence en numÃ©rique.

La numÃ©risation du signal est comparable Ã  l'utilisation d'un multimÃ¨tre pour mesurer une tension. Un convertisseur va prÃ©lever la valeur du signal, de faÃ§on rÃ©guliÃ¨re, au cours du temps.

Afin de correctement numÃ©riser un signal, il convient de dÃ©finir deux paramÃ¨tresÂ :

+ la vitesse de prÃ©lÃ¨vement, ou **frÃ©quence d'Ã©chantillonnage**
+ la plage de valeur permise pour le signal, ou **rÃ©solution de quantification**

## La frÃ©quence d'Ã©chantillonnage

Cette frÃ©quence dÃ©finit le nombre de prÃ©lÃ¨vements par seconde. Par exemple, un morceau Ã©ditÃ© sur un CD audio a une frÃ©quence d'Ã©chantillonnage de 44Â 100Â Hz (44,1Â kHz), cela signifie que le signal est mesurÃ© 44Â 100Â fois par seconde.

La frÃ©quence de travail la plus courante est 48Â kHz, mais l'on rencontre parfois des valeurs supÃ©rieures, multiple de celle-ciÂ : 96Â kHz, 192Â kHz, etc. Cette augmentation proportionnelle de la frÃ©quence d'Ã©chantillonnage s'appelle **surÃ©chantillonnage**. Certains techniciens espÃ¨rent, par le biais de ce surÃ©chantillonnage, amÃ©liorer la qualitÃ© de l'enregistrement.

Le surÃ©chantillonnage vient Ã©galement Ã  un coÃ»t de ressource et d'espace de stockage. Un flux audio Ã©chantillonnÃ© Ã  96Â kHz demande deux fois plus de ressource et d'espace qu'un flux Ã©chantillonnÃ© Ã  48Â kHz.

### Le thÃ©orÃ¨me de Shannon-Nyquist

Cette valeur initiale de 44Â 100Â Hz (ou 48Â kHz) n'a pas Ã©tÃ© choisie au hasard. Pour la comprendre, il faut revenir sur le phÃ©nomÃ¨ne que nous cherchons Ã  numÃ©riser.

Le son est une onde mÃ©canique, et nous l'entendons dans une plage de frÃ©quence comprise entre 20Â Hz (trÃ¨s grave) et 20Â 000Â Hz (trÃ¨s aigu). Il faut donc que notre systÃ¨me de numÃ©risation soit capable de reproduire une frÃ©quence maximale allant jusqu'Ã  20Â 000Â Hz. Pour cela, nous utilisons les rÃ©sultats des travaux des chercheurs Harry Nyquist et Claude Shannon (tous deux ayant travaillÃ© aux laboratoires Bell).

Le thÃ©orÃ¨me de Shannon-Nyquist stipule que, pour Ãªtre capable d'Ã©chantillonner un signal de frÃ©quence $f$, la frÃ©quence d'Ã©chantillonnage doit au moins Ãªtre de $2f$. Un ensemble de points gÃ©nÃ©rÃ© par une frÃ©quence ne peut correspondre qu'Ã  cette seule frÃ©quence. Notre plage d'Ã©coute Ã©tant limitÃ©e Ã  20Â kHz, la frÃ©quence d'Ã©chantillonnage minimale dont nous avons besoin est de 40Â kHz.

Que se passe-t-il si la frÃ©quence du signal dÃ©passe la moitiÃ© de la frÃ©quence d'Ã©chantillonnageÂ ? Dans ce cas, la vitesse de prÃ©lÃ¨vement n'est plus suffisante et nous observons l'apparition de nouvelles frÃ©quences ne provenant pas du signal original. Ce phÃ©nomÃ¨ne se nomme **repliement spectral**.

## La rÃ©solution de quantification

La rÃ©solution de quantification permet de dÃ©finir la plage de valeur dynamique permise dans le systÃ¨me numÃ©rique. Celle-ci s'exprime en 8Â bit. Par exemple, si nous prenons un convertisseur travaillant en 8Â bit. Sa valeur minimale, en binaire, est 0000 0000, ou encore 0 en baseÂ 10. Sa valeur maximale, en binaire, est 1111 1111, soit 255. Admettons que ce convertisseur accepte des signaux ayant une tension en entrÃ©e variant entre +15V et 0V, celles-ci seront respectivement affectÃ©es aux valeurs numÃ©riquesÂ 255 et 0. Si maintenant, ce convertisseur travaille en 16Â bit, ces valeurs seront affectÃ©es aux valeurs numÃ©riquesÂ 65535 et 0. La prÃ©cision de la mesure de la dynamique du signal n'est donc pas du tout la mÃªme.

En pratique, augmenter la rÃ©solution de quantification permet principalement de dÃ©finir le niveau de bruit du convertisseur. Plus la rÃ©solution est Ã©levÃ©e, plus le bruit se retrouvera faible. En 8Â bit, l'Ã©cart entre le niveau maximal d'un signal et le bruit est de 48Â dB, en 16Â bit cet Ã©cart est de 96Â dB, en 24Â bit, 144Â dB.

La rÃ©solution de quantification standard en enregistrement est 24Â bit. La plage dynamique est telle qu'elle rend le travail d'enregistrement beaucoup plus souple sur les niveaux d'acquisition des diffÃ©rentes sources.

## La "mauvaise rÃ©putation" du son numÃ©rique

Le son numÃ©rique a longtemps eu la rÃ©putation d'Ãªtre dur, particuliÃ¨rement dans le haut du spectre. Cela s'explique assez facilement par la mÃ©thode de fabrication des premiers convertisseurs.

En effet, toute la difficultÃ© de fabrication d'un convertisseur rÃ©side dans la rÃ©alisation d'un filtre anti-repliement. Ce filtre enlÃ¨ve les frÃ©quences au-dessus de la moitiÃ© de la frÃ©quence d'Ã©chantillonnage, afin de prÃ©venir tout repliement spectral. Ce type de filtre est extrÃªmement dÃ©licat Ã  rÃ©aliser en analogique. Ce problÃ¨me est rÃ©solu grÃ¢ce Ã  l'approche sigma-delta.

De plus, le **repliement spectral** parfois gÃ©nÃ©rÃ© par certains traitements (saturation, simulation analogique, compresseurs) n'a pas non plus aidÃ© Ã  la rÃ©putation du son numÃ©rique. En effets, lorsqu'il devient audible, le repliement spectral se caractÃ©rise par l'apparition de frÃ©quences **non harmoniques** souvent qualifiÃ©es de dures et dÃ©sagrÃ©ables. Il est cependant bon de rappeler que ce phÃ©nomÃ¨ne, certes bien rÃ©el, se produit aussi dans des conditions de saturation du signal importante et sur des sources sonores riches en aigus.

MalgrÃ© la vie dur que mÃ¨ne le son numÃ©rique dans l'inconscient collectif, il est important de rappeler qu'il a apportÃ© un grand nombre d'avantages sur le son analogique, **y compris sur des questions de rendus sonores**. Par exemple, la dynamique est bien plus importante, la distorsion involontaire du signal infime et l'ajout de bruit inexistant.

## La conversion sigma-delta

Aujourd'hui, les convertisseurs ne travaillent pas directement Ã  44,1Â kHz/16Â bit ou 48Â kHz/24Â bit. Ils utilisent Ã  la place un procÃ©dÃ© appelÃ© Ã©chantillonnage sigma-delta. Le principe est d'utiliser une frÃ©quence d'Ã©chantillonnage trÃ¨s rapide (384Â kHz) et de coder la dynamique du signal, en relatif, sur un seul bit (ce bit prend une valeur de 1 si le nouvel Ã©chantillon est plus fort que l'ancien, 0 pour le cas inverse). Les formats de travail que nous utilisons sont gÃ©nÃ©rÃ©s aprÃ¨s cette premiÃ¨re Ã©tape.

L'intÃ©rÃªt de cette mÃ©thode est doubleÂ :

+ Le signal est surÃ©chantillonnÃ© dÃ¨s l'enregistrement
+ Les filtres permettant d'Ã©viter le repliement spectral sont donc trÃ¨s simples Ã  rÃ©aliser

<!--chapter:end:08-les_convertisseurs.Rmd-->

# Les supports d'enregistrement numÃ©riques du son

<!--chapter:end:09-les_supports_d-enregistrements_numeriques.Rmd-->

# Les enceintes de monitoring

De tous les Ã©quipements audio nÃ©cessaires pour rÃ©aliser une prise de son, les enceintes (et les casques) sont certainement les plus importants. En effet, câ€™est sous leurs influences que nous pourrons Ã©couter et contrÃ´ler notre travail. Il est donc crucial dâ€™utiliser des Ã©coutes regroupant un certain nombre de critÃ¨res minimaux et de les connaÃ®tre sur le bout des doigts.

## Choisir une paire dâ€™Ã©coutes

Choisir une paire dâ€™enceintes peut paraÃ®tre Ãªtre un exercice difficile. Il existe Ã©normÃ©ment de modÃ¨les, parcourant des gammes de prix allant de quelques dizaines dâ€™euros Ã  plusieurs dizaines de milliers.

Qui plus est, lâ€™enceinte audio est sans doute lâ€™appareil audio que les Hommes savent le moins bien fabriquer. Lâ€™enceinte de monitoring parfait, Ã  savoir linÃ©aire en tout point, nâ€™existe pas.

PremiÃ¨rement, nous ne savons pas fabriquer des haut-parleurs capables de reproduire uniformÃ©ment toutes les frÃ©quences. Ces derniers sont souvent spÃ©cialisÃ©s dans une certaine plage de frÃ©quence. La plupart des enceintes de monitoring utilisent 3Â voiesÂ : deux actives (utilisant des haut-parleurs) pour lâ€™aigu et le mÃ©dium, et une passive (Ã©vent avant ou arriÃ¨re) pour le grave.

DeuxiÃ¨mement, un haut-parleur peut Ãªtre approchÃ© par un modÃ¨le Â«Â masse-ressortÂ Â». Cela signifie quâ€™il y a une certaine inertie Ã  sa mise en action et une certaine inertie Ã  sa mise en arrÃªt. Lâ€™enceinte idÃ©ale devrait possÃ©der une inertie nulle dans les deux cas, ce qui nâ€™est malheureusement pas le cas en pratique. Cette inertie est potentiellement responsable dâ€™un adoucissement des transitoires et dâ€™une sensation de flou. 

Il y a cependant plusieurs critÃ¨res assez objectifs pour Ã©valuer la qualitÃ© dâ€™une enceinteÂ :

1. La rÃ©ponse en frÃ©quenceÂ : lâ€™enceinte flatte-t-elle particuliÃ¨rement une zone du spectreÂ ? En dÃ©laisse-t-elle une autreÂ ?
2. La rÃ©ponse en transitoiresÂ : les attaques sont-elles respectÃ©esÂ ? Retrouve-t-on lâ€™Ã©nergie initiale du signalÂ ?
3. La linÃ©aritÃ© en fonction du volumeÂ : a-t-on une sensation de compression du signal lorsque lâ€™on augmente le niveau envoyÃ© dans lâ€™enceinteÂ ?
4. Le centre fantÃ´meÂ : le centre du systÃ¨me stÃ©rÃ©ophonique paraÃ®t-il stableÂ ? ParaÃ®t-il prÃ©cisÂ ?
5. La couleur sonore de lâ€™enceinteÂ : a-t-on plaisir Ã  Ã©couter du son et de la musique sur ce systÃ¨meÂ ?

## Placer correctement son Ã©coute

Afin de satisfaire les critÃ¨res de la stÃ©rÃ©ophonie, il convient de respecter les rÃ¨gles suivantesÂ :

+ Les deux enceintes doivent Ãªtre de mÃªme marque, de mÃªme modÃ¨le et appairÃ©e. Si une des membranes a dÃ» Ãªtre changÃ©e sur lâ€™une dâ€™elle, lâ€™autre aurait dÃ» recevoir la mÃªme opÃ©ration.
+ Les deux enceintes
+  doivent Ãªtre sÃ©parÃ©es dâ€™un angle de 60Â°
+ Lâ€™auditeur doit Ãªtre placÃ© Ã  Ã©quidistance des deux haut-parleurs, et regarder vers le milieu du segment formÃ© par les deux enceintes.

Une fois ces critÃ¨res respectÃ©s, voici quelques conseils sur le placement des enceintes dans une piÃ¨ceÂ :

+ On prÃ©fÃ©rera des piÃ¨ces de grandes tailles, afin de repousser au maximum le temps dâ€™arrivÃ©e des premiÃ¨res rÃ©flexions.
+ Le systÃ¨me stÃ©rÃ©ophonique devrait Ãªtre positionnÃ© dans un souci de symÃ©trieÂ : lâ€™enceinte de gauche ne devrait pas Ãªtre plus proche dâ€™un mur que lâ€™enceinte de droite, par exemple.
+ Dans le cas de petit espace, on prÃ©fÃ©ra coller les enceintes contre un mur. Cela permettra de supprimer lâ€™influence dâ€™une des premiÃ¨res rÃ©flexions au prix de lâ€™augmentation du niveau de grave.
+ Il est vivement recommandÃ© de procÃ©dÃ© au traitement, mÃªme minimal, acoustique de la piÃ¨ce de travail, Ã  commencer par les zones de rÃ©flexions premiÃ¨res et par les angles (ou le grave va sâ€™accumuler).
+ Si le traitement acoustique nâ€™est pas envisageable, il convient de privilÃ©gier une Ã©coute Ã  faible niveau et une proximitÃ© maximale avec les enceintes.

## L'Ã©coute au casque

Le casque est un outil permettant d'Ã©couter un signal tout en s'extrayant de son environnement (acoustique et/ou bruit). Cependant, de par son mode de fonctionnement, Ã  savoir deux haut-parleurs placÃ©s dans une enceinte en contact direct avec les oreilles, il gÃ©nÃ¨re un certain nombre de dÃ©formations.

PremiÃ¨rement, la stÃ©rÃ©ophonie Ã©coutÃ©e au casque est hypertrophiÃ©e. En effet, dans ces conditions d'Ã©coutes, l'oreille gauche n'entend que le haut-parleur gauche et l'oreille droite n'entend que le haut-parleur droit.

DeuxiÃ¨mement, il est trÃ¨s difficile de trouver des casques avec une rÃ©ponse en transitoire satisfaisante. Il convient donc d'Ãªtre excessivement prudent lorsque l'on mix du contenu percussif sur un casque.

TroisiÃ¨mement, les casques sont encore moins linÃ©aires en frÃ©quence que les haut-parleurs, il convient lÃ  aussi d'Ãªtre trÃ¨s prudent lors de la rÃ©alisation d'un mixage.

Ces dÃ©fauts peuvent Ãªtre compensÃ©s par l'habitude et la connaissance du systÃ¨me d'Ã©coute, mais la transportabilitÃ© d'un mixage (Ã  savoir, sa compatibilitÃ© avec d'autres systÃ¨mes d'Ã©coute) rÃ©alisÃ© au casque est souvent discutable.

## Casque fermÃ© ou casque ouvertÂ ?

Le casque fermÃ©, comme son nom l'indique, propose une fabrication enfermant le haut-parleur dans une enceinte close. Cette mÃ©thode de fabrication offre l'avantage d'isoler celui qui Ã©coute de l'environnement, mais aussi d'isoler l'environnement de ce qui est diffusÃ© dans le casque. Par contre, ces casques ont souvent une rÃ©ponse en frÃ©quence trÃ¨s accidentÃ©e, et ne sont pas recommandÃ©s pour le mixage. Il est par contre vivement recommandÃ© pour les musiciens en session de prise de son.

Le casque ouvert, Ã  l'inverse de son homologue fermÃ©, n'offre aucune isolation acoustique, au prix d'une meilleure rÃ©ponse en frÃ©quence du casque. Ces casques sont tout indiquÃ©s pour le mixage, mais beaucoup moins pour des situations de prise de son.

<!--chapter:end:10-les_enceintes.Rmd-->

# La prise de son au couple

La prise de son au couple stÃ©rÃ©ophonique regroupe lâ€™ensemble des techniques de prise de son dÃ©diÃ© au systÃ¨me dâ€™Ã©coute stÃ©rÃ©ophonique (deux enceintes sÃ©parÃ©es de 60Â° et orientÃ©es vers un auditeur placÃ© Ã  Ã©quidistance des deux transducteurs).

Ces techniques permettent une bien meilleure reprÃ©sentation des espaces des prises de son ainsi quâ€™une localisation des diffÃ©rents Ã©lÃ©ments enregistrÃ©s dans cet espace.

## GÃ©nÃ©ralitÃ©s sur les mÃ©canismes de la localisation du son par lâ€™oreille humaine

Afin de mieux comprendre comment fonctionne un couple de prise de son, il convient dâ€™Ã©tudier rapidement les principes fondamentaux de notre Ã©coute.

Notre capacitÃ© Ã  localiser les sons dans lâ€™espace repose principalement sur deux mÃ©canismesÂ :
+ La diffÃ©rence de temps
+ La diffÃ©rence de niveau

### La localisation par diffÃ©rence de temps

Nos oreilles sont espacÃ©es, dâ€™environ 15 Ã  25 cm. Cette distance implique quâ€™un son Ã©mis plus proche de lâ€™oreille droite arrivera Ã©galement plus tÃ´t quâ€™Ã  lâ€™oreille gauche. Cet Ã©cart de temps, de quelques millisecondes, est suffisant pour donner Ã  notre cerveau un indice sur la localisation du son.

Afin de sentir lâ€™ordre de grandeur en jeu, calculons la diffÃ©rence de temps ($\Delta t$) maximale pour un individu possÃ©dant un Ã©cart dâ€™oreille de 20 cm.

On sait que la cÃ©lÃ©ritÃ© du son dans lâ€™air vaut $c = 340 m.s^{-1}$, et est invariant en fonction de la frÃ©quence. On sait Ã©galement que $c = \frac{d}{t}$.

DÃ¨s lors, si on pose $d = 20 cm$ soit $d = 0.2 m$, on peut en dÃ©duire queÂ :

$t = \frac{d}{c} \iff t= \frac{0.2}{340} \approx 0.0006 s \approx 0.6 ms$

Afin de mettre en relief ce rÃ©sultat, il est communÃ©ment admis que lâ€™oreille humaine commence Ã  faire la diffÃ©rence entre deux rÃ©pÃ©titions dâ€™un mÃªme son Ã  partir de $20 ms$.

### La localisation par diffÃ©rence dâ€™intensitÃ©

A priori, lâ€™espace entre nos deux oreilles nâ€™est pas creux. La densitÃ© de notre crÃ¢ne et de son contenu va rÃ©flÃ©chir et absorber une partie des frÃ©quences rencontrÃ©es.

Ã‰galement, la partie externe de nos oreilles, appelÃ©es pavillon, permet, grÃ¢ce Ã  sa forme, de donner une directivitÃ© Ã  notre Ã©coute.

En dâ€™autres termes, notre tÃªte et le pavillon de nos oreilles se comportent comme un filtre, variant en fonction de lâ€™angle dâ€™incidence de la source. Cette altÃ©ration du timbre nâ€™est pas perÃ§ue comme une coloration, mais bien comme une information de localisation. La modÃ©lisation mathÃ©matique de ces filtres se retrouve dans la littÃ©rature scientifique sous le nom **HRTF**.

Cette attÃ©nuation sÃ©quentiellement dÃ©pendante est dÃ©cisive dans notre capacitÃ© Ã  localiser les sons. On la retrouve communÃ©ment sous le nom $\Delta i$.

### PrÃ©valence frÃ©quentielle de ces deux phÃ©nomÃ¨nes

Il est communÃ©ment admis que le $\Delta t$ aura une efficacitÃ© maximale dans les basses frÃ©quences, et le $\Delta i$ dans les hautes frÃ©quences.

## Principes de la prise de son au couple

Pour crÃ©er son effet stÃ©rÃ©ophonique, les couples de prise de son utilisent les mÃªmes mÃ©canismes que notre Ã©coute naturelleÂ :
+ La diffÃ©rence de temps
+ La diffÃ©rence dâ€™intensitÃ©

Il va de soi que, pour fonctionner de faÃ§on optimale, les microphones utilisÃ©s pour rÃ©aliser une prise de son stÃ©rÃ©ophonique doivent Ãªtre de mÃªme marque, de mÃªme modÃ¨le et appairÃ©e.

Afin de manipuler ces mÃ©canismes, le preneur de son peut jouer sur les paramÃ¨tres suivantÂ :
+ La directivitÃ© des microphones
+ Lâ€™angle entre les capsules
+ La distance entre les capsules

Modifier chacun de ses paramÃ¨tres influe sur lâ€™**angle de prise de son**. Plus lâ€™ange de prise de son est faible, plus lâ€™impression de stÃ©rÃ©ophonie sera grande. Plus lâ€™angle de prise de son est grand, plus lâ€™impression de stÃ©rÃ©ophonie sera faible, jusquâ€™Ã  tendre vers la monophonie.

> Attention de ne pas confondre lâ€™angle de prise de son avec lâ€™angle entre les capsules.

### Comment choisir un angle de prise de son.

Lâ€™angle de prise de son est Ã©troitement liÃ© Ã  la distance du couple par rapport Ã  lâ€™Ã©vÃ¨nement sonore Ã  enregistrer. En rÃ¨gle gÃ©nÃ©rale, plus le couple est loin des objets sonores Ã  enregistrer, plus son angle de prise de son sera faible. Ã€ lâ€™inverse, plus le couple sera proche, plus son angle de prise de son sera grand.

Ensuite, lors de la rÃ©alisation dâ€™un couple de prise de son, il est commun dâ€™enregistrer un ensemble dâ€™Ã©lÃ©mentsÂ : plusieurs instruments (batterie), voire plusieurs musiciens (quatuor Ã  corde, orchestre). Lâ€™objectif est bien souvent de retrouver une sensation de disposition des Ã©lÃ©ments dans lâ€™espace proche de la situation rÃ©elle. On cherche donc un angle de prise de son suffisamment petit pour que les sources occupent lâ€™intÃ©gralitÃ© de lâ€™espace stÃ©rÃ©ophonique, mais Ã©galement suffisamment grand pour ne pas crÃ©er une sensation de trou au centre.

### Comment rÃ©aliser un angle de prise de son.

Plusieurs outils existent pour aider le preneur de son Ã  configurer son angle de prise de son correctement.

Il est important de commencer par Ã©voquer les abaques de Michael Williams, ayant cherchÃ© Ã  Ã©tudier lâ€™angle de prise de son et ses qualitÃ©s en fonction des paramÃ¨tres vues prÃ©cÃ©demment. Les rÃ©sultats de ses travaux se trouvent sur le site [mmad.info](https://www.mmad.info/MAD/2%20Ch/2ch.htm).

On trouve Ã©galement beaucoup dâ€™application mobile, comme celle du constructeur du microphone Neumann, sâ€™appuyant sur les travaux de Michael Williams pour aider leurs utilisateurs Ã  correctement positionner leurs microphones. Ã‰videmment, et heureusement, rien nâ€™est spÃ©cifique Ã  un fabricant de microphones en particulier, lâ€™application dâ€™un constructeur A peut servir pour placer des microphones dâ€™un constructeur B.

Plus rÃ©cemment, des chercheurs britanniques ont dÃ©veloppÃ© une application dÃ©nommÃ©e [MARRS](https://marrsweb.hud.ac.uk/), permettant de positionner son couple de prise de son par rapport aux sources via une interface graphique trÃ¨s simple Ã  utiliser. Cette application est disponible sur mobile et sur navigateur internet.

### PrivilÃ©gier le $\Delta i$ ou le $\Delta t$Â ?

La diffÃ©rence de perception du champ stÃ©rÃ©ophonique est trÃ¨s diffÃ©rente entre celui produit par le $\Delta i$ ou par le $\Delta t$.

+ Un couple reposant sur le $\Delta i$ aura une sensation de localisation des sources prÃ©cise. De plus si un tel couple enregistre une source ce dÃ©plaÃ§ant a vitesse constante, la sensation de dÃ©placement retranscrite par le couple sera, elle aussi, linÃ©aire. Il est Ã©galement possible de sommer les deux microphones ensemble afin dâ€™obtenir un signal monophonique. Un tel couple est appelÃ© compatible mono.
+ Un couple reposant sur le $\Delta t$ aura une sensation de localisation plus floue, mais apportera un sens de lâ€™espace plus grand et une dimension spacieuse. Ã€ lâ€™inverse dâ€™un couple $\Delta i$, la sensation dâ€™un dÃ©placement linÃ©aire dâ€™une source nâ€™est pas linÃ©aire. Il nâ€™est pas possible de sommer les deux capsules pour en obtenir une rÃ©duction mono sans gÃ©nÃ©rer des altÃ©rations de timbre sÃ©vÃ¨res.

Chaque couple possÃ¨de ses avantages et ses inconvÃ©nients. Heureusement, nous ne sommes pas limitÃ©s Ã  lâ€™un oÃ¹ lâ€™autre et nous pouvons Ã  loisir rÃ©aliser une combinaison des deux mÃ©canismes.

## ComplÃ©ter une prise de son au couple par des appoints

Il est commun, lors dâ€™une prise de son au couple, de chercher Ã  obtenir une entiÃ¨re satisfaction sonore Ã  la seule aide du couple. Cependant, cela nâ€™est parfois pas possible, souvent pour des contraintes physiques et acoustiques (un instrument de lâ€™ensemble jouant moins fort que les autres). Dans ces cas, lâ€™utilisation dâ€™appoint, donc de microphone supplÃ©mentaire, placÃ© en proximitÃ© de la source, va permettre de venir rÃ©cupÃ©rer une prÃ©cision supplÃ©mentaire de lâ€™instrument.

Lors de lâ€™Ã©tape de mixage, le couple servira de base principale et lâ€™on viendra ajouter la quantitÃ© nÃ©cessaire dâ€™appoints pour prÃ©ciser le propos. Il sera parfois nÃ©cessaire de remettre en phase lâ€™appoint et le couple pour amÃ©liorer la sommation de lâ€™ensemble.

## Les topologies classiques de prise de son au couple

Le premier ingÃ©nieur Ã  se poser la question du son stÃ©rÃ©ophonique est lâ€™anglais Alan Blumlein en 1929. Il imagine lâ€™entiÃ¨retÃ© de la chaÃ®ne dâ€™enregistrement et de diffusion nÃ©cessaire Ã  la stÃ©rÃ©ophonie. Cependant, la BBC lui impose comme contrainte que toutes ses propositions soient compatibles avec des systÃ¨mes monophoniques. Il inventera donc le couple XY et MS.

Plus tard, la plupart des radios europÃ©ennes dÃ©velopperont des couples de prises de son mÃªlant $\Delta i$ et $\Delta t$, tel que lâ€™ORTF.

### Le couple Blumlein / XY

Les deux microphones sont ici directifs, placÃ©s au mÃªme point de lâ€™espace et ongulÃ© dâ€™une certaine valeur entre eux.

De par les contraintes technologiques de son Ã©poque, Blumlein a dÃ©crit ce couple pour une utilisation de deux microphones bidirectionnels. Il est aujourdâ€™hui plus commun de le rencontrer avec deux cardioÃ¯des.

Dans sa version originale, le couple Blumlein comprend donc deux microphones bidirectionnels avec un angle de 90Â°.

La formulation du couple XY comprend deux microphones cardioÃ¯des avec un angle compris entre 90Â° et 135Â°.

### Le couple MS

Le couple MS, Ã©galement inventÃ© par Alan Blumlein, permet de doser la quantitÃ© de stÃ©rÃ©ophonie aprÃ¨s lâ€™enregistrement.

Pour se faire, ce couple utilise deux microphonesÂ :
+ Un omnidirectionnel, historiquement, mais aujourdâ€™hui frÃ©quemment remplacÃ© par un microphone cardioÃ¯de.
+ Un bidirectionnel

Le microphone omnidirectionnel, ou cardioÃ¯de, va rendre compte du centre de la stÃ©rÃ©ophonie, tandis que le microphone bidirectionnel rendra compte de la latÃ©ralitÃ©.

Une fois enregistrÃ©s, ces deux canaux ont besoin dâ€™Ãªtre convertis, plus exactement dÃ©matricÃ©s, vers une paire de canaux stÃ©rÃ©ophonique. Lâ€™opÃ©ration est trÃ¨s simpleÂ :

$L = M+S$
$R = M-S$

Cette opÃ©ration peut Ãªtre rÃ©alisÃ©e sur une console de mixage, telle que dÃ©crite ci-dessous.

```{r chunk-label, echo = FALSE, fig.cap = 'DÃ©matriÃ§age MS'}
knitr::include_graphics(rep("_resources/171f157be4749ac8446dd9bdfff0625b.png"))
```

### Le couple ORTF

Le couple ORTF, inventÃ© par la radio franÃ§aise du mÃªme nom, combine lâ€™effet du $\Delta i$ et du $\Delta t$ afin de sâ€™approcher de lâ€™Ã©coute humaine.

Sa topologie est prÃ©cisÃ©ment dÃ©finie. Elle propose lâ€™utilisation dâ€™une paire de microphones cardioÃ¯de, ongulÃ© du 110Â° et avec un Ã©cart de 17 cm.

### Les couples AB

Les couples AB peuvent avoir une dÃ©finition ambiguÃ«. Une partie de la littÃ©rature scientifique considÃ¨re comme couple AB tout couple non coÃ¯ncident. Ã€ cet Ã©gard lâ€™ORTF est considÃ©rÃ© comme un couple AB. Pour dâ€™autre, les couples AB ne concernent que des couples constituÃ©s de microphones omnidirectionnels.

Ces derniers ont la particularitÃ© de nâ€™utiliser que le $\Delta t$ afin de placer les sources dans lâ€™espace. Le rendu est donc souvent spacieux, au prix dâ€™une certaine instabilitÃ© et dâ€™un certain manque de prÃ©cision de lâ€™image stÃ©rÃ©ophonique.

<!--chapter:end:11-le_couple_de_pds.Rmd-->

# MÃ©thodologie de prise de son

Le bon dÃ©roulement de lâ€™enregistrement dâ€™instruments acoustiques dÃ©pend de multiple facteur. TriÃ© par ordre dâ€™importance dÃ©croissante, nous trouvonsÂ :

1. Le confort du musicien
2. La qualitÃ© de lâ€™instrument enregistrÃ©
3. La qualitÃ© de lâ€™acoustique de la piÃ¨ce oÃ¹ a lieu lâ€™enregistrement
4. Le placement du microphone
5. Le choix du microphone (technologie et directivitÃ©)
6. Le choix du prÃ©ampli

## Le confort du musicien

MÃªme si elle peut sembler triviale, cette Â«Â Ã©tapeÂ Â» de la chaÃ®ne de prise de son est de loin la plus importante.
La qualitÃ© de lâ€™interprÃ©tation donnÃ©e par le musicien dÃ©pendra grandement de son Ã©tat moral et psychologiqueÂ :

+ Est-il stressÃ©
+ Est-il confiant
+ Se sent-il accueilli
+ etc.

Nous pourrions considÃ©rer quâ€™un ou une musicienne arrivant dans un studio dâ€™enregistrement se prÃ©sente avec un taux de confiance maximal envers lâ€™Ã©quipe technique. DÃ¨s lors lâ€™objectif des diffÃ©rents techniciens est de conserver cette jauge au maximum.

Les premiÃ¨res minutes sont particuliÃ¨rement importantes et va poser un ressenti fort sur la journÃ©e de travail. Il y a donc un Ã©quilibre Ã  trouver entre un accueil chaleureux et dÃ©contractÃ© et un rapport productiviste et sÃ©rieux.

Le systÃ¨me permettant aux musiciens de communiquer entre eux et avec les techniciens est primordial. En pratique, il nâ€™est pas rare de dÃ©dier certains microphones du plateau Ã  cette tÃ¢che. Du cÃ´tÃ© rÃ©gi, le Â«Â talkbackÂ Â» est lâ€™outil de communication premier des techniciens prÃ©sents sur la session. Il convient de lâ€™utiliser avec soin et prudence. Un musicien peut rapidement se sentir isolÃ©, sâ€™il enregistre seul. Il convient de maintenir un contact rÃ©gulier et prÃ©cis afin de ne pas lâ€™abandonner dans le seul dans sa cabine. Qui plus est, un quiproquo peut Ãªtre vite arrivÃ© avec les systÃ¨mes de talkback. Prudence quant Ã  lâ€™Ã©tat dâ€™ouverture ou de fermeture du microphone.

## Le choix de lâ€™instrument

La plupart des musiciens se prÃ©senteront avec leurs instruments. La marge de manÅ“uvre est donc ici quasi nulle.

Cependant il nâ€™est pas rare que le studio possÃ¨de du Â«Â backlineÂ Â», souvent composÃ© de batteries, dâ€™amplificateur guitare et basse, voire de guitares et de basses. Si lâ€™instrument utilisÃ© par le musicien pose problÃ¨me pour la prise de son, proposer une alternative peut sâ€™avÃ©rer Ãªtre un bon pari. Il convient Ã©videmment de sonder lâ€™ouverture du musicien par rapport Ã  cette proposition, afin de ne pas le braquer.

Il peut Ã©galement Ãªtre intÃ©ressant de Â«Â prÃ©parerÂ Â» les instruments. Cette technique est trÃ¨s courante sur les pianos et les batteries, afin de changer les propriÃ©tÃ©s acoustiques de lâ€™instrument grÃ¢ce a lâ€™utilisation de draps, coussins, couvertures disposÃ©es dans ou sur lâ€™instrument.

## Le choix de lâ€™acoustique

Lâ€™acoustique de la salle dâ€™enregistrement est-elle aussi plus souvent une contrainte quâ€™une variable dâ€™ajustement.

On prÃ©fÃ©rera souvent de grandes salles afin de limiter lâ€™apparition prÃ©maturÃ©e de premiÃ¨res rÃ©flexions. Plus la salle sera petite, plus celle-ci apportera une forte coloration sur le contenu enregistrÃ©. Il convient donc dâ€™Ãªtre attentif aux petites cabines de studio, celles-ci sont souvent trÃ¨s mates, mais leur apport sur le timbre des instruments qui y sont enregistrÃ©s est souvent trÃ¨s important.

Lorsque lâ€™on a la possibilitÃ© dâ€™enregistrer dans de grandes salles, il est souvent intÃ©ressant de disposer des quelques panneaux acoustiques mobiles, afin de modeler la piÃ¨ce Ã  sa convenance.

Si lâ€™acoustique imposÃ©e est dÃ©favorable, on prÃ©fÃ©rera dans ce cas des prises dâ€™hyper proximitÃ©, afin de minimiser son effet au maximum.

## Placer et choisir son microphone

En pratique, il est bien difficile de dissocier le choix du microphone de son placement, les deux Ã©tant trÃ¨s interdÃ©pendants. Cependant, il convient de garder Ã  lâ€™esprit que le positionnement du microphone est, parmi les deux, sans doute le plus dÃ©terminant.

La premiÃ¨re Ã©tape, avant mÃªme de choisir un microphone, consiste Ã  Ã©couter lâ€™instrument dans lâ€™acoustique dâ€™enregistrement. Il sâ€™agit ici dâ€™une Ã©coute active. On se dÃ©place autour de lâ€™instrument, on sâ€™en approche, on sâ€™en Ã©loigne, afin de sentir lâ€™interaction entre la source et lâ€™acoustique du lieu. Aussi, il est important de trouver deux zones dâ€™Ã©mission particuliÃ¨re de lâ€™instrumentÂ : la zone de projection maximale et la zone au timbre le plus favorable. La premiÃ¨re peut nous servir Ã  positionner lâ€™instrumentiste par rapport aux autres instruments afin de minimiser les reprises entre microphones. La deuxiÃ¨me zone nous indique lâ€™axe de prise de son.

Cette zone au timbre le plus favorable est relative. Elle dÃ©pend de lâ€™instrument, bien sÃ»r, mais aussi du modÃ¨le. Elle dÃ©pend Ã©galement du mode de jeu, de lâ€™articulation du joueur et Ã©videmment, de lâ€™esthÃ©tique de la musique.

### Le rapport a la distance du microphone

La distance de positionnement du microphone est un Ã©lÃ©ment excessivement important sur le rendu esthÃ©tique de la prise de son.

En rÃ¨gle gÃ©nÃ©rale, plus on prend de distance, plus on approche une prise de son naturaliste, cherchant Ã  reproduire un Ã©vÃ¨nement sonore dans son environnement, tel quâ€™il aurait Ã©tÃ© entendu dans la piÃ¨ce. Plus on se rapproche, plus on fragmente lâ€™Ã©vÃ©nement sonore et plus on lâ€™arrache aussi a son contexte de diffusion.

Afin de dÃ©terminer efficacement le placement dâ€™un microphone, il convient dâ€™abord dâ€™en connaÃ®tre sa distance critique. Celle-ci correspond au point, dans une piÃ¨ce, oÃ¹ le son provenant directement dâ€™une source est perÃ§u au mÃªme niveau sonore que la rÃ©ponse acoustique Ã  cette source. Cela signifie que si nous plaÃ§ons notre microphone au-delÃ  de ce point, nous obtiendrons plus dâ€™acoustique que de son direct de lâ€™instrument.

Il est important aussi de considÃ©rer que la directivitÃ© du microphone influe sur la distance critique. En effet, plus la directivitÃ© du microphone est large (tends vers lâ€™omnidirectionnalitÃ©), plus le microphone paraÃ®tra Ã©loignÃ© de la source. Ã€ lâ€™inverse, plus la directivitÃ© dâ€™un microphone est Ã©troite (tends vers la bidirectionnalitÃ©), plus le microphone paraÃ®tra proche.

Dans le cas de lâ€™utilisation de microphone directif, le placement en proximitÃ© et hyperproximitÃ© va crÃ©er une accentuation du contenu basse-frÃ©quence de la source. Cela devient parfois un Ã©lÃ©ment esthÃ©tique, comme sur les voix radiophoniques. Cela aussi peut Ãªtre un dÃ©faut, une exagÃ©ration quâ€™il conviendra de corriger en postproduction.

### Quand choisir une prise de son stÃ©rÃ©ophonique

La prise de son stÃ©rÃ©ophonique, comme son nom lâ€™indique, regroupe lâ€™ensemble des techniques de prise de son dÃ©diÃ© au systÃ¨me de diffusion stÃ©rÃ©ophonique (deux enceintes sÃ©parÃ©es de 60Â° et orientÃ©es vers un auditeur placÃ© Ã  Ã©quidistance des deux transducteurs).

Lâ€™avantage de tels dispositifs de prises de son est de peupler dÃ¨s la prise lâ€™espace stÃ©rÃ©ophonique qui est donnÃ© Ã  lâ€™auditeur lors de la diffusion. Ils permettent Ã©galement de rendre compte de la position de plusieurs Ã©vÃ¨nements sonores ayant lieu dans la mÃªme acoustique. Cette derniÃ¨re est dâ€™ailleurs bien mieux retranscrite par de tels systÃ¨mes de prise de son.

Il sâ€™agit Ã  nouveau dâ€™un choix esthÃ©tique. Faire le choix dâ€™une prise de son monophonique permet de renforcer la sensation de frontalitÃ© et de densitÃ© dâ€™une source. Ã€ lâ€™inverse, une prise de son stÃ©rÃ©ophonique donnera une dÃ©finition spatiale accrue.

### Quand choisir le multi-microphonie

La multi-microphonie consiste Ã  enregistrer un instrument via lâ€™utilisation de microphones (principalement) directifs, placÃ©s Ã  diffÃ©rents endroits jugÃ©s pertinents et en hyperproximitÃ©.

Cette approche esthÃ©tique de la prise de son est devenue indissociable des Â«Â musiques actuellesÂ Â». Elle offre lâ€™avantage dâ€™une grande flexibilitÃ© de traitement lors de la phase de mixage. Voir, elle implique une certaine partie des traitements.

En effet, une prise dâ€™hyperproximitÃ© va systÃ©matiquement relever deux dÃ©fautsÂ :
+ un effet de proximitÃ©Â : le grave/bas mÃ©dium de la source paraÃ®t hypertrophiÃ© lors de lâ€™emploi de microphones directifs.
+ Les dynamiques de jeux sont Ã©galement hypertrophiÃ©es.

Lâ€™effet de proximitÃ© implique donc bien souvent lâ€™utilisation dâ€™un Ã©galiseur, permettant de corriger cette augmentation artificielle du grave. De mÃªme, lâ€™hypertrophie de la dynamique de jeu implique lâ€™usage dâ€™un compresseur afin de corriger ces variations artificielles.

Afin de recrÃ©er une sensation de spatialisation, on utilisera principalement deux outils. En premier lieu, le potentiomÃ¨tre de panoramique afin de diriger ces sons mono dans lâ€™espace stÃ©rÃ©ophonique, puis les rÃ©verbÃ©rations artificielles permettra de reconstituer un champ acoustique et de rÃ©intÃ©grer ces sources dans une scÃ¨ne sonore.

Si lâ€™approche de la prise au couple pouvait Ãªtre qualifiÃ©e de naturaliste, alors la prise de son en multimicrophone sera son pendant spectaculaire. Ã‰videmment, il convient de ne pas aussi franchement opposer ces deux approches et il existe tout un monde de systÃ¨me de prise de son entre ces deux extrÃªmes.

## Le choix du prÃ©amplificateur

Le rÃ´le du prÃ©amplificateur est dâ€™amplifier le signal, le tout en ramenant le minimum de bruit. Un premier Ã©lÃ©ment de choix de prÃ©ampli va se faire sur le niveau de pression acoustique produit par les sources Ã  enregistrer.

Enregistrer une batterie impose peut de contrainte sur le prÃ©ampli quand a sa capacitÃ© Ã  amplifier sans rajouter beaucoup de bruit sur le signal. Ã€ lâ€™inverse, enregistrer des instruments peux sonores, possiblement avec des microphones peux sensibles, implique lâ€™utilisation de prÃ©ampli avec une excellente rÃ©serve de gain et un excellent rapport signal bruit.

### Lâ€™influence du prÃ©ampli sur la Â«Â couleurÂ Â» du son

Il est assez connu que le prÃ©ampli peut Ã©galement devenir un choix esthÃ©tique pour influencer la couleur dâ€™une prise de son. Cette question semble assez complexe. Voici quelques Ã©lÃ©ments de rÃ©ponseÂ :

+ Le choix du prÃ©ampli est dâ€™une influence minime par rapport Ã  **tous** les autres choix prÃ©cÃ©demment fait.
+ Les prÃ©amplis sont souvent catÃ©gorisÃ©s, en termes de couleur, via les composants utilisÃ©s pour rÃ©aliser lâ€™amplification. Attention, un composant Ã©lectronique dÃ©pend toujours du contexte dans lequel il est placÃ© (ici, du circuit Ã©lectronique). Il est donc difficile de prÃ©cisÃ©ment qualifier le son dâ€™un prÃ©ampli Ã  lampe ou Ã  transistor de faÃ§on gÃ©nÃ©rique.
+ Les impÃ©dances dâ€™entrÃ©e des prÃ©amplis ne sont souvent pas Ã©voquÃ©es dans ces discussions. Hors, pour la plus parts des microphones (hors statiques), leur impÃ©dance de sortie peut Ãªtre suffisamment Ã©levÃ©e pour engendrer une dÃ©perdition en aigu et en transitoire. Cette dÃ©perdition peut Ãªtre heureuse, ou malheureuse, mais surtout bien rÃ©elle. Une maniÃ¨re de sâ€™en prÃ©munir peut-Ãªtre dâ€™utiliser des Â«Â boosterÂ Â» de microphones (parfois Ã©galement appelÃ©s prÃ©amplis), permettant dâ€™augmenter le niveau de sortie des microphones et aussi dâ€™adapter leur impÃ©dance. 

<!--chapter:end:12-methodologie_de_pds.Rmd-->

# Les causes de dÃ©phasage

## Les effets sonores de dÃ©phasage

Tous les signaux sont caractÃ©risÃ©s par une certaine phase. Celle-ci est moins tangible que celles de niveau sonore ou de frÃ©quence. En effet, lorsquâ€™un signal est Ã©coutÃ© seul, celle-ci ne sâ€™entend pas. Câ€™est au moment oÃ¹ plusieurs signaux corrÃ©lÃ©s (comprendre, enregistrÃ©s au mÃªme moment, par plusieurs microphones) sont sommÃ©s que les diffÃ©rences de phase peuvent sâ€™entendre.

## Approche mathÃ©matique

Prenons lâ€™exemple dâ€™un son purÂ :
$sin (\omega t + \phi)$ oÃ¹ $\omega = 2\pi f$

La phase de ce signal est dÃ©crite par $\omega t +\phi$

Les deux paramÃ¨tres responsables de dÃ©phasages audibles sontÂ :
+ $t$, le temps
+ $\phi$, la phase Ã  lâ€™origine

Attention, pour un son pur, lâ€™effet de la modification de $t$ ou de $\phi$ semble trÃ¨s similaire. Ce nâ€™est pas le cas pour des signaux pseudo-pÃ©riodiques, attÃ©nuÃ©s dans le temps.

## Les sources de dÃ©phasage

Les causes les plus classiques de dÃ©phasages sontÂ :

+ Un cÃ¢ble XLR avec une inversion sur le point chaud et le point froid
+ Une prise de son avec une diffÃ©rence de distance entre deux microphones
+ Une prise de son utilisant deux microphones positionnÃ©s de part et dâ€™autre dâ€™une membrane
+ Un retard de certaines frÃ©quences liÃ© aux objets rencontrÃ©s par les signaux

<!--chapter:end:13-les_causes_de_dÃ©phasage.Rmd-->

# Gestion des circuits d'Ã©coutes

bla

<!--chapter:end:14-gestion_des_circuits_d_ecoutes.Rmd-->

